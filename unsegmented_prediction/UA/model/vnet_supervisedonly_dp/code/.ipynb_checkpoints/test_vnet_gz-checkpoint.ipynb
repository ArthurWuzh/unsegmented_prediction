{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "uuid": "2c086cdd-6be7-4bd4-a69a-298bf1a12da6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from networks.vnet import VNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "uuid": "c1109c72-3e02-4d41-afd1-d425c99f4536"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import math\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from medpy import metric\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "\n",
    "def predict_and_center_cut_all_case(net, image_list, num_classes, \n",
    "                        patch_size=(112, 112, 80), stride_xy=18, stride_z=4, \n",
    "                        save_result=True, test_save_path=None, preproc_fn=None,\n",
    "                        device='cpu'):\n",
    "    for image_path in tqdm(image_list):\n",
    "        id = image_path.split('/')[-2]\n",
    "        print(id,':')\n",
    "        out_dir = test_save_path+id\n",
    "        if not os.path.isdir(out_dir):\n",
    "            os.mkdir(out_dir)\n",
    "            \n",
    "        h5f = h5py.File(image_path, 'r')\n",
    "        image = h5f['image'][:]\n",
    "        if preproc_fn is not None:\n",
    "            image = preproc_fn(image)\n",
    "        label_pred, score_map = test_single_case(\n",
    "            net, image, \n",
    "            stride_xy, stride_z, patch_size, \n",
    "            num_classes=num_classes, \n",
    "            device=device)\n",
    "        \n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "        filter_mask = filter_connected_domain(label_pred,num_keep_region=None,ratio_keep=0.001)\n",
    "        filter_mask = (filter_mask>0).astype(float)\n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "        label_pred = label_pred*filter_mask\n",
    "\n",
    "        # 发现圆形视场的边界处经常出现错误分割(轮廓线),因此需要手动过滤\n",
    "        r = label_pred.shape[0]/2\n",
    "        xc,yc = label_pred.shape[0]/2,label_pred.shape[0]/2\n",
    "#         filter_mask = np.ones(label_pred.shape)\n",
    "#         for x in range(label_pred.shape[0]):\n",
    "#             for y in range(label_pred.shape[1]):\n",
    "#                 filter_mask[x,y,:] = 0 if r*0.5<np.sqrt((x-xc)**2+(y-yc)**2)<r*2 else 1\n",
    "#         label_pred = filter_mask*label_pred\n",
    "        \n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "        # onehot\n",
    "        label_onehot_pred = tf.keras.utils.to_categorical(label_pred)\n",
    "        if not label_onehot_pred.shape[-1]==3:\n",
    "            print(id+' onehot shape error: miss one or more pixel class')\n",
    "            continue\n",
    "            \n",
    "        # center cut\n",
    "        tempL = np.nonzero(label_pred)\n",
    "        minx, maxx = np.min(tempL[0]).astype(int), np.max(tempL[0]).astype(int)\n",
    "        miny, maxy = np.min(tempL[1]).astype(int), np.max(tempL[1]).astype(int)\n",
    "        minz, maxz = np.min(tempL[2]).astype(int), np.max(tempL[2]).astype(int)\n",
    "        image = image[minx:maxx+1, miny:maxy+1, minz:maxz+1]\n",
    "        label_pred = label_pred[minx:maxx+1, miny:maxy+1, minz:maxz+1]\n",
    "        label_onehot_pred = label_onehot_pred[minx:maxx+1, miny:maxy+1, minz:maxz+1, :]\n",
    "            \n",
    "        # case 拼接\n",
    "        numd = []\n",
    "        for d in range(label_pred.shape[2]):\n",
    "            numd.append( len(np.where(label_pred[:,:,d].flatten()==2)[0]) )\n",
    "        numd = np.array(numd)\n",
    "        slice = int(np.where(numd==numd.max())[0][0])\n",
    "        fig = plt.figure( frameon=False)#dpi=100, \n",
    "        image_unstd = (image-image.min())/(image.max()-image.min())*255\n",
    "        npimg = np.append( image_unstd[:,:,slice],label_pred[:,:,slice]/2*255,axis=1 )\n",
    "        plt.imshow(npimg.astype(int),cmap='plasma')#一定要转为int\n",
    "        plt.savefig( test_save_path + id + str(slice) + \"_pred.png\" )\n",
    "        plt.show()\n",
    "        \n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "        \n",
    "        if save_result:\n",
    "            # save files\n",
    "            filename = os.path.join(os.path.dirname(image_path),'center_cut.h5')\n",
    "            f = h5py.File(filename, 'w')\n",
    "            f.create_dataset('image', data=image.astype(np.float32), compression=\"gzip\")\n",
    "#             f.create_dataset('label', data=label_onehot_pred.astype(np.int), compression=\"gzip\")\n",
    "            f.close()\n",
    "#             nib.save(nib.Nifti1Image(image[:].astype(np.float32), np.eye(4)), \n",
    "#                      out_dir+ '/' + id +'_minx%d_maxx%d_miny%d_maxy%d_minz%d_maxz%d'%(minx,maxx,miny,maxy,minz,maxz)+ \"_img.nii.gz\")\n",
    "#             nib.save(nib.Nifti1Image(label_pred.astype(np.float32), np.eye(4)), \n",
    "#                      out_dir+ '/' + id +'_minx%d_maxx%d_miny%d_maxy%d_minz%d_maxz%d'%(minx,maxx,miny,maxy,minz,maxz)+ \"_pred.nii.gz\")\n",
    "#             nib.save(nib.Nifti1Image(label_onehot_pred[:].astype(np.float32), np.eye(4)), \n",
    "#                      out_dir+ '/' + id +'_minx%d_maxx%d_miny%d_maxy%d_minz%d_maxz%d'%(minx,maxx,miny,maxy,minz,maxz)+ \"_label_onehot_pred.nii.gz\")\n",
    "    print('All finished')\n",
    "\n",
    "\n",
    "# -\n",
    "\n",
    "from skimage import measure\n",
    "def filter_connected_domain(image,num_keep_region=100,ratio_keep=None):\n",
    "    \"\"\"\n",
    "    原文链接：https://blog.csdn.net/a563562675/article/details/107066836\n",
    "    return label of filter \n",
    "    \"\"\"\n",
    "    # 标记输入的3D图像\n",
    "    label, num = measure.label(image, connectivity=1, background=0, return_num=True)\n",
    "    if num < 1:\n",
    "        return image\n",
    "\n",
    "    # 获取对应的region对象\n",
    "    region = measure.regionprops(label)\n",
    "    # 获取每一块区域面积并排序\n",
    "    num_list = [i for i in range(0, num)]\n",
    "    area_list = [region[i].area for i in num_list]\n",
    "    \n",
    "    # 去除面积较小的连通域\n",
    "    if ratio_keep:\n",
    "        max_region_area = np.array(area_list).max()\n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "        drop_list = np.where(area_list<max_region_area*ratio_keep)[0]\n",
    "        for i in drop_list:\n",
    "            label[region[i-1].slice][region[i-1].image] = 0 \n",
    "    \n",
    "    else:\n",
    "        if len(num_list) > num_keep_region:\n",
    "            num_list_sorted = sorted(num_list, key=lambda x: area_list[x])[::-1]# 面积由大到小排序\n",
    "            for i in num_list_sorted[num_keep_region:]:\n",
    "                # label[label==i] = 0\n",
    "                label[region[i-1].slice][region[i-1].image] = 0\n",
    "#             num_list_sorted = num_list_sorted[:num_keep_region]\n",
    "    import pdb\n",
    "    pdb.set_trace()\n",
    "    return label\n",
    "\n",
    "\n",
    "def test_all_case(\n",
    "    net, image_list, \n",
    "    num_classes, patch_size=(112, 112, 80), stride_xy=18, stride_z=4, \n",
    "    save_result=True, test_save_path=None, preproc_fn=None,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    \n",
    "    metrics = pd.DataFrame(columns=['bg','proximal femur','distal femur','fragment']) \n",
    "    total_metric = 0.0\n",
    "    for image_path in tqdm(image_list):\n",
    "        id = image_path.split('/')[-2]\n",
    "        h5f = h5py.File(image_path, 'r')\n",
    "        image = h5f['image'][:]\n",
    "        label = np.argmax(h5f['label'][:],axis=-1)\n",
    "        print('label:',label.shape)\n",
    "        print('image:',image.shape)\n",
    "        if preproc_fn is not None:\n",
    "            image = preproc_fn(image)\n",
    "        prediction, score_map = test_single_case(net, image, stride_xy, stride_z, patch_size, num_classes=num_classes, device=\"cuda\")\n",
    "\n",
    "        print('prediction:',prediction.shape)\n",
    "        \n",
    "        if np.sum(prediction)==0:\n",
    "            single_metric = (0,0,0,0)\n",
    "        else:\n",
    "            single_metric = calculate_metric_percase(prediction, label[:], num_classes)\n",
    "        total_metric += np.asarray(single_metric)\n",
    "        \n",
    "        print(id,':')\n",
    "        print(\"single_metric:\",single_metric)\n",
    "        \n",
    "        metrics.loc[id] = single_metric\n",
    "        if save_result:\n",
    "            nib.save(nib.Nifti1Image(prediction.astype(np.float32), np.eye(4)), test_save_path + id + \"_pred.nii.gz\")\n",
    "            nib.save(nib.Nifti1Image(image[:].astype(np.float32), np.eye(4)), test_save_path + id + \"_img.nii.gz\")\n",
    "            nib.save(nib.Nifti1Image(label[:].astype(np.float32), np.eye(4)), test_save_path + id + \"_gt.nii.gz\")\n",
    "    avg_metric = total_metric / len(image_list)\n",
    "    print('average metric is:\\n{}'.format(avg_metric))\n",
    "\n",
    "    return avg_metric, metrics\n",
    "\n",
    "\n",
    "def test_single_case(net, image, stride_xy, stride_z, patch_size, num_classes=1, device=\"cuda\"):\n",
    "    w, h, d = image.shape\n",
    "\n",
    "    # if the size of image is less than patch_size, then padding it\n",
    "    add_pad = False\n",
    "    if w < patch_size[0]:\n",
    "        w_pad = patch_size[0]-w\n",
    "        add_pad = True\n",
    "    else:\n",
    "        w_pad = 0\n",
    "    if h < patch_size[1]:\n",
    "        h_pad = patch_size[1]-h\n",
    "        add_pad = True\n",
    "    else:\n",
    "        h_pad = 0\n",
    "    if d < patch_size[2]:\n",
    "        d_pad = patch_size[2]-d\n",
    "        add_pad = True\n",
    "    else:\n",
    "        d_pad = 0\n",
    "    wl_pad, wr_pad = w_pad//2,w_pad-w_pad//2\n",
    "    hl_pad, hr_pad = h_pad//2,h_pad-h_pad//2\n",
    "    dl_pad, dr_pad = d_pad//2,d_pad-d_pad//2\n",
    "    if add_pad:\n",
    "        image = np.pad(image, [(wl_pad,wr_pad),(hl_pad,hr_pad), (dl_pad, dr_pad)], mode='constant', constant_values=0)\n",
    "    ww,hh,dd = image.shape\n",
    "\n",
    "    sx = math.ceil((ww - patch_size[0]) / stride_xy) + 1\n",
    "    sy = math.ceil((hh - patch_size[1]) / stride_xy) + 1\n",
    "    sz = math.ceil((dd - patch_size[2]) / stride_z) + 1\n",
    "    print(\"{}, {}, {}\".format(sx, sy, sz))\n",
    "    score_map = np.zeros((num_classes, ) + image.shape).astype(np.float32)\n",
    "    cnt = np.zeros(image.shape).astype(np.float32)\n",
    "\n",
    "    for x in range(0, sx):\n",
    "        xs = min(stride_xy*x, ww-patch_size[0])\n",
    "        for y in range(0, sy):\n",
    "            ys = min(stride_xy * y,hh-patch_size[1])\n",
    "            for z in range(0, sz):\n",
    "                zs = min(stride_z * z, dd-patch_size[2])\n",
    "                test_patch = image[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]]\n",
    "                test_patch = np.expand_dims(np.expand_dims(test_patch,axis=0),axis=0).astype(np.float32)\n",
    "                #test_patch = torch.from_numpy(test_patch).cuda()# gpu\n",
    "                test_patch = torch.from_numpy(test_patch).to(device)# cpu\n",
    "                y1 = net(test_patch)\n",
    "                y = F.softmax(y1, dim=1)\n",
    "                y = y.cpu().data.numpy()\n",
    "                y = y[0,:,:,:,:]\n",
    "                score_map[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] += y\n",
    "                cnt[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] += 1\n",
    "    score_map = score_map/np.expand_dims(cnt,axis=0)\n",
    "    label_map = np.argmax(score_map, axis = 0)\n",
    "    if add_pad:\n",
    "        label_map = label_map[wl_pad:wl_pad+w,hl_pad:hl_pad+h,dl_pad:dl_pad+d]\n",
    "        score_map = score_map[:,wl_pad:wl_pad+w,hl_pad:hl_pad+h,dl_pad:dl_pad+d]\n",
    "    return label_map, score_map\n",
    "\n",
    "def cal_dice(prediction, label, num=2):\n",
    "    total_dice = np.zeros(num-1)\n",
    "    for i in range(1, num):\n",
    "        prediction_tmp = (prediction==i)\n",
    "        label_tmp = (label==i)\n",
    "        prediction_tmp = prediction_tmp.astype(np.float)\n",
    "        label_tmp = label_tmp.astype(np.float)\n",
    "\n",
    "        dice = 2 * np.sum(prediction_tmp * label_tmp) / (np.sum(prediction_tmp) + np.sum(label_tmp))\n",
    "        total_dice[i - 1] += dice\n",
    "\n",
    "    return total_dice\n",
    "\n",
    "def calculate_metric_percase(pred, gt, num_classes):\n",
    "    \"二分类、多分类的指标统计\"\n",
    "    if num_classes is None:\n",
    "        num_classes = len(np.unique(gt))#注意：gt不是onehot编码\n",
    "    print('np.unique(gt):',np.unique(gt))\n",
    "    if num_classes==2:\n",
    "        dice = metric.binary.dc(pred, gt)\n",
    "        jc = metric.binary.jc(pred, gt)\n",
    "        hd = metric.binary.hd95(pred, gt)\n",
    "        asd = metric.binary.asd(pred, gt)\n",
    "    elif num_classes>2:\n",
    "        from keras.utils import to_categorical\n",
    "        gt_onehot = to_categorical(gt, num_classes)\n",
    "        pred_onehot = to_categorical(pred, num_classes)\n",
    "        print('gt:',gt_onehot.shape)\n",
    "        print('pred:',pred_onehot.shape)\n",
    "        dice = []\n",
    "        jc = []\n",
    "        hd = []\n",
    "        asd = []\n",
    "        for k in range(num_classes):\n",
    "            pred_k = pred_onehot[...,k]\n",
    "            gt_k = gt_onehot[...,k]\n",
    "            dice +=  [metric.dc(result=pred_k, reference=gt_k)]\n",
    "            #jc += [metric.jc(result=pred_k, reference=gt_k)]\n",
    "            #hd += [metric.hd95(result=pred_k, reference=gt_k)]\n",
    "            #asd += [metric.asd(result=pred_k, reference=gt_k)]\n",
    "    else:\n",
    "        raise ValueError(\"pred和gt不能是onehot编码\")\n",
    "    return dice#, jc#, hd, asd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "uuid": "2ae333ad-bd41-48b6-89d4-157b5571a120"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--root_path', type=str, default='../../data/gz_dataset/segmented', help='Folder of Test Set')\n",
    "parser.add_argument('--model', type=str,  default='vnet_supervisedonly_dp', help='model_name')\n",
    "parser.add_argument('--gpu', type=str,  default='0', help='GPU to use')\n",
    "FLAGS = parser.parse_args(args=[])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "uuid": "a54496e1-8fe6-45bb-aab4-f6f9e57e119d"
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = FLAGS.gpu\n",
    "snapshot_path = \"../model/\"+FLAGS.model+\"/\"\n",
    "test_save_path = \"../model/prediction/\"+FLAGS.model+\"_post/\"\n",
    "if not os.path.exists(test_save_path):\n",
    "    os.makedirs(test_save_path)\n",
    "\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "uuid": "4c417ed1-1d6d-441d-b458-59496b0ca407"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_list:  ['../../data/gz_dataset/segmented/100201344/mri_norm2.h5', '../../data/gz_dataset/segmented/100207091/mri_norm2.h5', '../../data/gz_dataset/segmented/100301649/mri_norm2.h5', '../../data/gz_dataset/segmented/100658440/mri_norm2.h5', '../../data/gz_dataset/segmented/100752370/mri_norm2.h5', '../../data/gz_dataset/segmented/100903938/mri_norm2.h5', '../../data/gz_dataset/segmented/100067245/mri_norm2.h5', '../../data/gz_dataset/segmented/100218737/mri_norm2.h5']\n"
     ]
    }
   ],
   "source": [
    "with open(FLAGS.root_path + '/../test.list', 'r') as f:\n",
    "    image_list = f.readlines()\n",
    "image_list = [os.path.join(FLAGS.root_path,item.replace('\\n', ''),\"mri_norm2.h5\") for item in image_list]\n",
    "print(\"image_list: \",image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "uuid": "f0b131b2-f823-4c5e-a26b-8813e7d467cd"
   },
   "outputs": [],
   "source": [
    "def test_calculate_metric(epoch_num, patch_size=(128, 128, 64), stride_xy=64, stride_z=32):\n",
    "    print(\"test_calculate_metric\")\n",
    "    net = VNet(n_channels=1, n_classes=num_classes, normalization='batchnorm', has_dropout=False).cuda()\n",
    "    save_mode_path = os.path.join(snapshot_path, 'iter_' + str(epoch_num) + '.pth')\n",
    "    net.load_state_dict(torch.load(save_mode_path))\n",
    "    print(\"init weight from {}\".format(save_mode_path))\n",
    "    net.eval()\n",
    "\n",
    "    avg_metric,metrics = test_all_case(net, image_list, num_classes=num_classes,\n",
    "                               patch_size=patch_size, stride_xy=stride_xy, stride_z=stride_z,\n",
    "                               save_result=True, test_save_path=test_save_path)\n",
    "\n",
    "    return avg_metric, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "uuid": "fa33a9b5-4aae-4b85-8e51-43456d3c314d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin\n",
      "test_calculate_metric\n",
      "init weight from ../model/vnet_supervisedonly_dp/iter_6001.pth\n",
      "2, 2, 3\n",
      "prediction: (164, 160, 109)\n",
      "label: (229, 229, 124)\n",
      "image: (164, 160, 109)\n",
      "np.unique(gt): [0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt: (229, 229, 124, 4)\n",
      "pred: (164, 160, 109, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (164,160,109) (229,229,124) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5da854cf3783>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"begin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mavg_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_calculate_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_xy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_z\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_save_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'metrics_test_set.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-024ae976acff>\u001b[0m in \u001b[0;36mtest_calculate_metric\u001b[0;34m(epoch_num, patch_size, stride_xy, stride_z)\u001b[0m\n\u001b[1;32m      9\u001b[0m     avg_metric,metrics = test_all_case(net, image_list, num_classes=num_classes,\n\u001b[1;32m     10\u001b[0m                                \u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_xy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride_xy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_z\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride_z\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                save_result=True, test_save_path=test_save_path)\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mavg_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-d472d71cc7c1>\u001b[0m in \u001b[0;36mtest_all_case\u001b[0;34m(net, image_list, num_classes, patch_size, stride_xy, stride_z, save_result, test_save_path, preproc_fn, device)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0msingle_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0msingle_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_metric_percase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mtotal_metric\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-d472d71cc7c1>\u001b[0m in \u001b[0;36mcalculate_metric_percase\u001b[0;34m(pred, gt, num_classes)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mpred_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_onehot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mgt_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt_onehot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             \u001b[0mdice\u001b[0m \u001b[0;34m+=\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgt_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m             \u001b[0;31m#jc += [metric.jc(result=pred_k, reference=gt_k)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;31m#hd += [metric.hd95(result=pred_k, reference=gt_k)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/medpy/metric/binary.py\u001b[0m in \u001b[0;36mdc\u001b[0;34m(result, reference)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mintersection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0msize_i1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (164,160,109) (229,229,124) "
     ]
    }
   ],
   "source": [
    "print(\"begin\")\n",
    "avg_metric, metrics = test_calculate_metric(6001, patch_size=(128, 128, 64), stride_xy=64, stride_z=32)\n",
    "print(avg_metric)\n",
    "metrics.to_csv(os.path.join(test_save_path,'metrics_test_set.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "520f7293-9268-44c3-b8cc-50d673295cd1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
