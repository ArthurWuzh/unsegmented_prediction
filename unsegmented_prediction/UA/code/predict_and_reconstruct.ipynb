{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true,
    "uuid": "26b07ad6-1d2a-45ea-bd35-7659ca0e9b1d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init weight from ../model/vnet_supervisedonly_dp/iter_6001.pth\n",
      "100201344 :\n",
      "type <class 'SimpleITK.SimpleITK.Image'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oldspacing [0.447266 0.447266 1.25    ]\n",
      "imageoldshape: [512, 512, 99]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-fc36e904ab7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0mpredict_and_construct_all_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_xy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_z\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-fc36e904ab7b>\u001b[0m in \u001b[0;36mpredict_and_construct_all_case\u001b[0;34m(epoch_num, patch_size, stride_xy, stride_z, device)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0mpredict_and_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_xy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-fc36e904ab7b>\u001b[0m in \u001b[0;36mpredict_and_construct\u001b[0;34m(net, listt, stride_xy, stride_z, patch_size, num_classes, device, old_replaced)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mimageoldshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetArrayFromImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_sitk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"imageoldshape:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimageoldshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0msegoldshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetArrayFromImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_sitk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"segoldshape:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msegoldshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mlabeloldshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetArrayFromImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_onehot_sitk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from networks.vnet import VNet\n",
    "#from test_util import  predict_and_center_cut_all_case, test_single_case, calculate_metric_percase\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import sys\n",
    "#sys.path.append('./dataloaders')\n",
    "#from utils import resample_image3D, sitk_onehot_transform, make_out_itk, array_replace, plot_slice_sample\n",
    "\n",
    "from tqdm import tqdm\n",
    "import SimpleITK as sitk\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--root_path', type=str, default='../data/CTM_dataset/unSegmented', help='Folder of Test Set')\n",
    "# parser.add_argument('--model', type=str,  default='vnet_supervisedonly_dp', help='model_name')\n",
    "# parser.add_argument('--gpu', type=str,  default='0', help='GPU to use')\n",
    "# FLAGS = parser.parse_args()\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = FLAGS.gpu\n",
    "# snapshot_path = \"../model/\"+FLAGS.model+\"/\"\n",
    "# test_save_path = \"../model/prediction/\"+FLAGS.model+\"_post/\"\n",
    "\n",
    "\n",
    "root_path='../../data/gz_dataset/segmented'\n",
    "model='vnet_supervisedonly_dp'#'VNet_Binary_CTM'\n",
    "gpu='0'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu\n",
    "snapshot_path = \"../model/\"+model+\"/\"\n",
    "# test_save_path = \"../model/prediction/unSegmented/\"+model+\"_post/\"\n",
    "test_save_path = \"../model/prediction/reconstruct/\"+model\n",
    "#test_save_path = \"../model/prediction/\"+model+\"_post/\"\n",
    "if not os.path.exists(test_save_path):\n",
    "    os.makedirs(test_save_path)\n",
    "\n",
    "num_classes = 4#2\n",
    "output_size =[128, 128, 64]\n",
    "with open(root_path + '/../test.list', 'r') as f:\n",
    "    image_list = f.readlines()\n",
    "image_list = [os.path.join(root_path,item.replace('\\n', ''),\"CT.nrrd\") for item in image_list]\n",
    "\n",
    "def predict_and_construct(\n",
    "    net,listt,\n",
    "    stride_xy, stride_z, patch_size, num_classes=1, device=\"cuda\",\n",
    "    old_replaced=\"CT.nrrd\"):\n",
    "\n",
    "    for item in tqdm(listt):\n",
    "        sample_name = item.split('/')[-2]\n",
    "        print(sample_name,':')#win系统改为'\\\\'\n",
    "        \n",
    "        # read image\n",
    "        image_sitk = sitk.ReadImage(item)\n",
    "        print(\"type\", type(image_sitk))\n",
    "        seg_sitk = sitk.ReadImage(item.replace(old_replaced, 'Segmentation.seg.nrrd'))#label_onehot_origin_sitk\n",
    "        label_sitk = sitk.ReadImage(item.replace(old_replaced, 'Segmentation-label.nrrd'))\n",
    "        label_onehot_sitk = sitk_onehot_transform(label_sitk)\n",
    "        \n",
    "        label_name = [\n",
    "            'bg',\n",
    "            seg_sitk.GetMetaData('Segment0_Name'),\n",
    "            seg_sitk.GetMetaData('Segment1_Name'),\n",
    "            seg_sitk.GetMetaData('Segment2_Name') \n",
    "            ]#人工标注的类别顺序\n",
    "        newspacing = [1.0, 1.0, 1.0]\n",
    "        oldspacing = np.abs(image_sitk.GetSpacing())\n",
    "        print(\"oldspacing\",oldspacing)\n",
    "        imageoldshape = list(sitk.GetArrayFromImage(image_sitk).transpose((2,1,0)).shape)\n",
    "        print(\"imageoldshape:\",imageoldshape)\n",
    "        segoldshape = list(sitk.GetArrayFromImage(seg_sitk).transpose((2,1,0)).shape)\n",
    "        print(\"segoldshape:\",segoldshape)\n",
    "        labeloldshape = list(sitk.GetArrayFromImage(label_onehot_sitk).transpose((2,1,0,3)).shape)\n",
    "        image = resample_image3D(image_sitk,newspacing,method='Linear')\n",
    "        print(\"labeloldshape:\",labeloldshape)\n",
    "        label_onehot = resample_image3D(label_onehot_sitk,newspacing,method='Nearest')\n",
    "        \n",
    "        # get array\n",
    "        print(\"label_name:\",label_name)\n",
    "        image = sitk.GetArrayFromImage(image).transpose((2,1,0))#tanspose之后才能与sitk.GetSize匹配\n",
    "        label_onehot = np.round( sitk.GetArrayFromImage(label_onehot) ).transpose((2,1,0,3))#tanspose之后才能与sitk.GetSize匹配\n",
    "        label = sitk.GetArrayFromImage(label_sitk).transpose((2,1,0)).astype('uint8')#np.argmax(label_onehot,axis=-1)\n",
    "        #plot_slice_sample(image,label,np.nonzero(label)[2].max(),fn=False)\n",
    "        \n",
    "        # 灰度标准化\n",
    "        image = (image - np.mean(image)) / np.std(image)\n",
    "        image = image.astype(np.float32)\n",
    "        \n",
    "        ## 调整类别顺序&合并骨头到背景中，注意：是onehot编码\n",
    "        target_name = ['bg','proximal femur','diastal femur','fragment']#目标类别顺序\n",
    "        idx = [label_name.index(name) for name in target_name]\n",
    "        assert len(idx)==4,'one or more classes missed'\n",
    "        label_onehot = label_onehot[:,:,:,idx]\n",
    "\n",
    "        '''## bone归入背景类\n",
    "        bg = label_onehot[:,:,:,[0,1]].sum(axis=-1)[:,:,:,np.newaxis]\n",
    "        label_onehot = np.concatenate((bg,label_onehot[:,:,:,2:]),axis=-1)\n",
    "        assert (np.unique(label_onehot) == [0, 1]).all(), \"1: pixel class error\"\n",
    "        ## 转化为非onehot编码以便作图'''\n",
    "        label = np.argmax(label_onehot, axis=-1).astype('uint8')\n",
    "        \n",
    "        # cut( center cut)\n",
    "        tempL = np.nonzero(label)\n",
    "        minx, maxx = np.min(tempL[0]), np.max(tempL[0])\n",
    "        miny, maxy = np.min(tempL[1]), np.max(tempL[1])\n",
    "        minz, maxz = np.min(tempL[2]), np.max(tempL[2])\n",
    "        w, h, d = label.shape\n",
    "        px = max(output_size[0] - (maxx-minx+1), 0) // 2\n",
    "        py = max(output_size[1] - (maxy-miny+1), 0) // 2\n",
    "        #pz = max(output_size[2] - (maxz-minz+1), 0) // 2\n",
    "        minx = max(minx - np.random.randint(10, 20) - px, 0)\n",
    "        maxx = min(maxx + np.random.randint(10, 20) + px, w-1)\n",
    "        miny = max(miny - np.random.randint(10, 20) - py, 0)\n",
    "        maxy = min(maxy + np.random.randint(10, 20) + py, h-1)\n",
    "        image_cut = image[minx:maxx+1, miny:maxy+1, minz:maxz+1]\n",
    "        label_cut = label[minx:maxx+1, miny:maxy+1, minz:maxz+1]\n",
    "        label_onehot_cut = label_onehot[minx:maxx+1, miny:maxy+1, minz:maxz+1, :]\n",
    "        print(\"cut image.shape:\",image.shape, \"cut label.shape:\",label.shape)\n",
    "        #plot_slice_sample(image_cut,label_cut,int((maxx-minx)/2),fn=False)\n",
    "        \n",
    "        \n",
    "        # predict\n",
    "        label_cut_pred, score_cut_pred = test_single_case(net, image_cut, stride_xy, stride_z, patch_size, num_classes=num_classes, device=\"cuda\")\n",
    "        # get metric\n",
    "        single_metric = calculate_metric_percase(label_cut_pred, label_cut, num_classes)\n",
    "        print(single_metric)\n",
    "        \n",
    "        # 将cut之后的图像的预测值恢复为原图大小：\n",
    "        #image = resample_image3D(image,oldspacing,method='Linear')\n",
    "        \n",
    "        print(\"return:\",image.shape)\n",
    "        tmp = np.zeros(image.shape)\n",
    "        tmp[minx:maxx+1, miny:maxy+1, minz:maxz+1] = label_cut_pred\n",
    "        label_pred = tmp.astype('uint8')\n",
    "        #label_pred = \n",
    "        \n",
    "        label_onehot_pred = to_categorical(label_pred)\n",
    "        offset = seg_sitk.GetMetaData('Segmentation_ReferenceImageExtentOffset')\n",
    "        offset = [int(fs) for fs in offset.split()]\n",
    "        print(\"sitk.GetArrayFromImage(seg_sitk): \",sitk.GetArrayFromImage(seg_sitk).shape)\n",
    "        shape = sitk.GetArrayFromImage(seg_sitk).transpose(2,1,0).shape\n",
    "        label_onehot_pred = label_onehot_pred[\n",
    "            offset[0]:offset[0]+shape[0],\n",
    "            offset[1]:offset[1]+shape[1],\n",
    "            offset[2]:offset[2]+shape[2],\n",
    "            1:\n",
    "        ].astype('uint8')\n",
    "        #plot_slice_sample(image,label_pred,np.nonzero(label)[2].max(),fn=False)\n",
    "        \n",
    "        #try:\n",
    "            # generate sitk object\n",
    "        label_pred_sitk = sitk.GetImageFromArray(label_pred.transpose(2,1,0))\n",
    "        label_pred_sitk = resample_image3D(label_pred_sitk,oldspacing,imageoldshape,method='Linear')\n",
    "        label_pred_sitk.CopyInformation(label_sitk)\n",
    "        label_onehot_pred_sitk = sitk.GetImageFromArray(label_onehot_pred.transpose(2,1,0,3))\n",
    "        label_onehot_pred_sitk = resample_image3D(label_onehot_pred_sitk,oldspacing,labeloldshape,method='Nearest')\n",
    "        #test = list(sitk.GetArrayFromImage(label_onehot_pred_sitk).transpose((2,1,0,3)).shape)\n",
    "        #print(\"test\",test)\n",
    "        label_onehot_pred_sitk.CopyInformation(seg_sitk)\n",
    "\n",
    "            # save to nrrd file\n",
    "        sitk.WriteImage(label_onehot_pred_sitk, item.replace(old_replaced, 'Segmentation-pred.seg.nrrd'))\n",
    "        sitk.WriteImage(label_pred_sitk, item.replace(old_replaced, 'Segmentation-pred-label.nrrd'))\n",
    "        #except:\n",
    "            #print('case %s:generate asd save sitk error, skip this case'%sample_name)\n",
    "\n",
    "        \n",
    "def predict_and_construct_all_case(\n",
    "    epoch_num, \n",
    "    patch_size=(128, 128, 64), \n",
    "    stride_xy=64, \n",
    "    stride_z=32,\n",
    "    device='cuda'\n",
    "):\n",
    "    \n",
    "    net = VNet(n_channels=1, n_classes=num_classes, normalization='batchnorm', has_dropout=False).to(device)\n",
    "    save_mode_path = os.path.join(snapshot_path, 'iter_' + str(epoch_num) + '.pth')\n",
    "    net.load_state_dict(torch.load(save_mode_path))\n",
    "    print(\"init weight from {}\".format(save_mode_path))\n",
    "    net.eval()\n",
    "    \n",
    "    predict_and_construct(net,image_list, stride_xy, stride_z, patch_size, num_classes=num_classes, device=device)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    predict_and_construct_all_case(6001, patch_size=(128, 128, 64), stride_xy=64, stride_z=32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "uuid": "d07edde1-81ec-4140-906b-d36b9af1b177"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure\n",
    "import scipy.ndimage as nd\n",
    "import SimpleITK as sitk\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def recursive_glob(rootdir='.', suffix=''):\n",
    "    \"\"\"Performs recursive glob with given suffix and rootdir\n",
    "        :param rootdir is the root directory\n",
    "        :param suffix is the suffix to be searched\n",
    "    \"\"\"\n",
    "    return [os.path.join(looproot, filename)\n",
    "        for looproot, _, filenames in os.walk(rootdir)\n",
    "        for filename in filenames if filename.endswith(suffix)]\n",
    "\n",
    "def get_cityscapes_labels():\n",
    "    return np.array([\n",
    "        # [  0,   0,   0],\n",
    "        [128, 64, 128],\n",
    "        [244, 35, 232],\n",
    "        [70, 70, 70],\n",
    "        [102, 102, 156],\n",
    "        [190, 153, 153],\n",
    "        [153, 153, 153],\n",
    "        [250, 170, 30],\n",
    "        [220, 220, 0],\n",
    "        [107, 142, 35],\n",
    "        [152, 251, 152],\n",
    "        [0, 130, 180],\n",
    "        [220, 20, 60],\n",
    "        [255, 0, 0],\n",
    "        [0, 0, 142],\n",
    "        [0, 0, 70],\n",
    "        [0, 60, 100],\n",
    "        [0, 80, 100],\n",
    "        [0, 0, 230],\n",
    "        [119, 11, 32]])\n",
    "\n",
    "def get_pascal_labels():\n",
    "    \"\"\"Load the mapping that associates pascal classes with label colors\n",
    "    Returns:\n",
    "        np.ndarray with dimensions (21, 3)\n",
    "    \"\"\"\n",
    "    return np.asarray([[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],\n",
    "                       [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],\n",
    "                       [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],\n",
    "                       [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],\n",
    "                       [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n",
    "                       [0, 64, 128]])\n",
    "\n",
    "\n",
    "def encode_segmap(mask):\n",
    "    \"\"\"Encode segmentation label images as pascal classes\n",
    "    Args:\n",
    "        mask (np.ndarray): raw segmentation label image of dimension\n",
    "          (M, N, 3), in which the Pascal classes are encoded as colours.\n",
    "    Returns:\n",
    "        (np.ndarray): class map with dimensions (M,N), where the value at\n",
    "        a given location is the integer denoting the class index.\n",
    "    \"\"\"\n",
    "    mask = mask.astype(int)\n",
    "    label_mask = np.zeros((mask.shape[0], mask.shape[1]), dtype=np.int16)\n",
    "    for ii, label in enumerate(get_pascal_labels()):\n",
    "        label_mask[np.where(np.all(mask == label, axis=-1))[:2]] = ii\n",
    "    label_mask = label_mask.astype(int)\n",
    "    return label_mask\n",
    "\n",
    "\n",
    "def decode_seg_map_sequence(label_masks, dataset='pascal'):\n",
    "    rgb_masks = []\n",
    "    for label_mask in label_masks:\n",
    "        rgb_mask = decode_segmap(label_mask, dataset)\n",
    "        rgb_masks.append(rgb_mask)\n",
    "    rgb_masks = torch.from_numpy(np.array(rgb_masks).transpose([0, 3, 1, 2]))\n",
    "    return rgb_masks\n",
    "\n",
    "def decode_segmap(label_mask, dataset, plot=False):\n",
    "    \"\"\"Decode segmentation class labels into a color image\n",
    "    Args:\n",
    "        label_mask (np.ndarray): an (M,N) array of integer values denoting\n",
    "          the class label at each spatial location.\n",
    "        plot (bool, optional): whether to show the resulting color image\n",
    "          in a figure.\n",
    "    Returns:\n",
    "        (np.ndarray, optional): the resulting decoded color image.\n",
    "    \"\"\"\n",
    "    if dataset == 'pascal':\n",
    "        n_classes = 21\n",
    "        label_colours = get_pascal_labels()\n",
    "    elif dataset == 'cityscapes':\n",
    "        n_classes = 19\n",
    "        label_colours = get_cityscapes_labels()\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    r = label_mask.copy()\n",
    "    g = label_mask.copy()\n",
    "    b = label_mask.copy()\n",
    "    for ll in range(0, n_classes):\n",
    "        r[label_mask == ll] = label_colours[ll, 0]\n",
    "        g[label_mask == ll] = label_colours[ll, 1]\n",
    "        b[label_mask == ll] = label_colours[ll, 2]\n",
    "    rgb = np.zeros((label_mask.shape[0], label_mask.shape[1], 3))\n",
    "    rgb[:, :, 0] = r / 255.0\n",
    "    rgb[:, :, 1] = g / 255.0\n",
    "    rgb[:, :, 2] = b / 255.0\n",
    "    if plot:\n",
    "        plt.imshow(rgb)\n",
    "        plt.show()\n",
    "    else:\n",
    "        return rgb\n",
    "\n",
    "def generate_param_report(logfile, param):\n",
    "    log_file = open(logfile, 'w')\n",
    "    # for key, val in param.items():\n",
    "    #     log_file.write(key + ':' + str(val) + '\\n')\n",
    "    log_file.write(str(param))\n",
    "    log_file.close()\n",
    "\n",
    "def cross_entropy2d(logit, target, ignore_index=255, weight=None, size_average=True, batch_average=True):\n",
    "    n, c, h, w = logit.size()\n",
    "    # logit = logit.permute(0, 2, 3, 1)\n",
    "    target = target.squeeze(1)\n",
    "    if weight is None:\n",
    "        criterion = nn.CrossEntropyLoss(weight=weight, ignore_index=ignore_index, size_average=False)\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss(weight=torch.from_numpy(np.array(weight)).float().cuda(), ignore_index=ignore_index, size_average=False)\n",
    "    loss = criterion(logit, target.long())\n",
    "\n",
    "    if size_average:\n",
    "        loss /= (h * w)\n",
    "\n",
    "    if batch_average:\n",
    "        loss /= n\n",
    "\n",
    "    return loss\n",
    "\n",
    "def lr_poly(base_lr, iter_, max_iter=100, power=0.9):\n",
    "    return base_lr * ((1 - float(iter_) / max_iter) ** power)\n",
    "\n",
    "\n",
    "def get_iou(pred, gt, n_classes=21):\n",
    "    total_iou = 0.0\n",
    "    for i in range(len(pred)):\n",
    "        pred_tmp = pred[i]\n",
    "        gt_tmp = gt[i]\n",
    "\n",
    "        intersect = [0] * n_classes\n",
    "        union = [0] * n_classes\n",
    "        for j in range(n_classes):\n",
    "            match = (pred_tmp == j) + (gt_tmp == j)\n",
    "\n",
    "            it = torch.sum(match == 2).item()\n",
    "            un = torch.sum(match > 0).item()\n",
    "\n",
    "            intersect[j] += it\n",
    "            union[j] += un\n",
    "\n",
    "        iou = []\n",
    "        for k in range(n_classes):\n",
    "            if union[k] == 0:\n",
    "                continue\n",
    "            iou.append(intersect[k] / union[k])\n",
    "\n",
    "        img_iou = (sum(iou) / len(iou))\n",
    "        total_iou += img_iou\n",
    "\n",
    "    return total_iou\n",
    "\n",
    "def get_dice(pred, gt):\n",
    "    total_dice = 0.0\n",
    "    pred = pred.long()\n",
    "    gt = gt.long()\n",
    "    for i in range(len(pred)):\n",
    "        pred_tmp = pred[i]\n",
    "        gt_tmp = gt[i]\n",
    "        dice = 2.0*torch.sum(pred_tmp*gt_tmp).item()/(1.0+torch.sum(pred_tmp**2)+torch.sum(gt_tmp**2)).item()\n",
    "        print(dice)\n",
    "        total_dice += dice\n",
    "\n",
    "    return total_dice\n",
    "\n",
    "def get_mc_dice(pred, gt, num=2):\n",
    "    # num is the total number of classes, include the background\n",
    "    total_dice = np.zeros(num-1)\n",
    "    pred = pred.long()\n",
    "    gt = gt.long()\n",
    "    for i in range(len(pred)):\n",
    "        for j in range(1, num):\n",
    "            pred_tmp = (pred[i]==j)\n",
    "            gt_tmp = (gt[i]==j)\n",
    "            dice = 2.0*torch.sum(pred_tmp*gt_tmp).item()/(1.0+torch.sum(pred_tmp**2)+torch.sum(gt_tmp**2)).item()\n",
    "            total_dice[j-1] +=dice\n",
    "    return total_dice\n",
    "\n",
    "def post_processing(prediction):\n",
    "    prediction = nd.binary_fill_holes(prediction)\n",
    "    label_cc, num_cc = measure.label(prediction,return_num=True)\n",
    "    total_cc = np.sum(prediction)\n",
    "    measure.regionprops(label_cc)\n",
    "    for cc in range(1,num_cc+1):\n",
    "        single_cc = (label_cc==cc)\n",
    "        single_vol = np.sum(single_cc)\n",
    "        if single_vol/total_cc<0.2:\n",
    "            prediction[single_cc]=0\n",
    "\n",
    "    return prediction\n",
    "\n",
    "\n",
    "# +\n",
    "def resample_image3D(\n",
    "    image3D,\n",
    "    newspacing=[1.0,1.0,1.0],\n",
    "    newsize=None,\n",
    "    method='Linear',):\n",
    "    \"\"\"做插值\"\"\"\n",
    "    resample = sitk.ResampleImageFilter()\n",
    "    if method == 'Linear':\n",
    "        resample.SetInterpolator(sitk.sitkLinear)\n",
    "    elif method == 'Nearest':\n",
    "        resample.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "    resample.SetOutputDirection(image3D.GetDirection())\n",
    "    resample.SetOutputOrigin(image3D.GetOrigin())\n",
    "    resample.SetOutputSpacing(newspacing)\n",
    "\n",
    "    if not newsize:\n",
    "        newsize = np.round(np.array(image3D.GetSize())*np.abs(image3D.GetSpacing())/np.array(newspacing)).astype('int').tolist()\n",
    "    resample.SetSize(newsize)\n",
    "    # resample.SetDefaultPixelValue(0)\n",
    "\n",
    "    newimage = resample.Execute(image3D)\n",
    "    return newimage\n",
    "\n",
    "def sitk_onehot_transform(image):\n",
    "    image_array = sitk.GetArrayFromImage(image)\n",
    "    label_array_onehot = to_categorical(image_array)\n",
    "    image_onehot = sitk.GetImageFromArray(label_array_onehot)\n",
    "    image_onehot.SetOrigin(image.GetOrigin())\n",
    "    image_onehot.SetDirection(image.GetDirection())\n",
    "    image_onehot.SetSpacing(image.GetSpacing())\n",
    "    return image_onehot\n",
    "\n",
    "def make_out_itk(image,image_sitk):\n",
    "    out_image_sitk = sitk.GetImageFromArray(image)\n",
    "    out_image_sitk.SetSpacing(image_sitk.GetSpacing())\n",
    "    out_image_sitk.SetOrigin(image_sitk.GetOrigin())\n",
    "    out_image_sitk.SetDirection(image_sitk.GetDirection())\n",
    "    return out_image_sitk\n",
    "\n",
    "# 数组替换元素\n",
    "def array_replace(array,olds,news):\n",
    "    # 不适用于onehot\n",
    "    #olds:list of old value\n",
    "    #news:list of new value\n",
    "    olds = np.array(olds)\n",
    "    news = np.array(news)\n",
    "    offset = olds.max()*10\n",
    "    tmps = olds+offset\n",
    "    array += offset\n",
    "    for tmp,new in zip(tmps,news):\n",
    "        array[array==tmp] = new\n",
    "    return array\n",
    "\n",
    "\n",
    "# -\n",
    "def plot_slice_sample(image,label,d,fn=False):\n",
    "    fig = plt.figure()\n",
    "    a = fig.add_subplot(1, 2, 1)\n",
    "    imgplot = plt.imshow(image[:,:,d].squeeze())\n",
    "    a.set_title('image')\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "    a = fig.add_subplot(1, 2, 2)\n",
    "    imgplot = plt.imshow(label[:,:,d].squeeze())\n",
    "    imgplot.set_clim(0.0, 3.0)\n",
    "    a.set_title('label')\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "    if fn:\n",
    "        plt.savefig(fn)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "uuid": "c2d98e87-4724-4469-a74d-5a2c6682d225"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# +\n",
    "import h5py\n",
    "import math\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from medpy import metric\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "def predict_and_center_cut_single_case(\n",
    "    net,image_path,out_dir,num_classes,\n",
    "    patch_size=(112, 112, 80), stride_xy=18, stride_z=4, \n",
    "    save_result=True, test_save_path=None, \n",
    "    preproc_fn=None,\n",
    "    device='cpu'\n",
    "):\n",
    "    # 预测并最小包络切割单个样本\n",
    "    \n",
    "    if not os.path.isdir(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "        \n",
    "    h5f = h5py.File(image_path, 'r')\n",
    "    image = h5f['image'][:]\n",
    "    if preproc_fn is not None:\n",
    "        image = preproc_fn(image)\n",
    "    label_pred, score_map = test_single_case(\n",
    "        net, image, \n",
    "        stride_xy, stride_z, patch_size, \n",
    "        num_classes=num_classes, \n",
    "        device=device)\n",
    "        \n",
    "    # 发现圆形视场的边界处经常出现错误分割(轮廓线),因此需要手动过滤\n",
    "    r = label_pred.shape[0]/2\n",
    "    xc,yc = label_pred.shape[0]/2,label_pred.shape[0]/2\n",
    "    filter_mask = np.ones(label_pred.shape)\n",
    "    for x in range(label_pred.shape[0]):\n",
    "        for y in range(label_pred.shape[1]):\n",
    "            filter_mask[x,y,:] = 0 if r*0.6<np.sqrt((x-xc)**2+(y-yc)**2)<r*2 else 1\n",
    "    label_pred = filter_mask*label_pred\n",
    "        \n",
    "    # 过滤掉小的连通域\n",
    "    filter_mask = filter_connected_domain(label_pred,min_region_area=100,num_keep_region=None,ratio_keep=None)\n",
    "    filter_mask = (filter_mask>0).astype(float)\n",
    "    label_pred = label_pred*filter_mask\n",
    "        \n",
    "    # onehot\n",
    "    label_onehot_pred = tf.keras.utils.to_categorical(label_pred)\n",
    "    if not label_onehot_pred.shape[-1]==num_classes:\n",
    "        print(id+' onehot shape error: miss one or more pixel class')\n",
    "        return None\n",
    "            \n",
    "    # center cut\n",
    "    tempL = np.nonzero(label_pred)\n",
    "    minx, maxx = np.min(tempL[0]).astype(int), np.max(tempL[0]).astype(int)\n",
    "    miny, maxy = np.min(tempL[1]).astype(int), np.max(tempL[1]).astype(int)\n",
    "    minz, maxz = np.min(tempL[2]).astype(int), np.max(tempL[2]).astype(int)\n",
    "    image = image[minx:maxx+1, miny:maxy+1, minz:maxz+1]\n",
    "    label_pred = label_pred[minx:maxx+1, miny:maxy+1, minz:maxz+1]\n",
    "    label_onehot_pred = label_onehot_pred[minx:maxx+1, miny:maxy+1, minz:maxz+1, :]\n",
    "        \n",
    "    # image & laberl & pred 拼接\n",
    "    numd = []\n",
    "    for d in range(label_pred.shape[2]):\n",
    "        numd.append( len(np.where(label_pred[:,:,d].flatten()==(num_classes-1))[0]) )\n",
    "    numd = np.array(numd)\n",
    "    slice = int(np.where(numd==numd.max())[0][0])\n",
    "    fig = plt.figure( frameon=False)#dpi=100, \n",
    "    image_unstd = (image-image.min())/(image.max()-image.min())*255\n",
    "    npimg = np.append( image_unstd[:,:,slice],label_pred[:,:,slice]/(num_classes-1)*255,axis=1 )\n",
    "    plt.imshow(npimg.astype(int),cmap='plasma')#一定要转为int\n",
    "    plt.savefig(  os.path.join(out_dir, \"center_cut_pred.png\") )\n",
    "    plt.show()\n",
    "    \n",
    "    return image,label_pred\n",
    "    \n",
    "def predict_and_center_cut_all_case(\n",
    "    net, image_list, num_classes, \n",
    "    patch_size=(112, 112, 80), stride_xy=18, stride_z=4, \n",
    "    save_result=True, test_save_path=None, \n",
    "    preproc_fn=None,\n",
    "    device='cpu'):\n",
    "    \n",
    "    for image_path in tqdm(image_list):\n",
    "        id = image_path.split('/')[-2]\n",
    "        print(id,':')\n",
    "        out_dir = os.path.join(test_save_path ,id) \n",
    "        try:\n",
    "            image,label_pred = predict_and_center_cut_single_case(\n",
    "                net,\n",
    "                image_path,\n",
    "                out_dir,\n",
    "                num_classes,\n",
    "                patch_size, stride_xy, stride_z, \n",
    "                save_result, test_save_path, \n",
    "                preproc_fn,\n",
    "                device\n",
    "            )\n",
    "            if save_result:\n",
    "                # save files\n",
    "                filename = os.path.join(out_dir,'center_cut.h5')\n",
    "                f = h5py.File(filename, 'w')\n",
    "                f.create_dataset('image', data=image.astype(np.float32), compression=\"gzip\")\n",
    "    #             f.create_dataset('label', data=label_onehot_pred.astype(np.int), compression=\"gzip\")\n",
    "                f.close()\n",
    "    #             nib.save(nib.Nifti1Image(image[:].astype(np.float32), np.eye(4)), \n",
    "    #                      out_dir+ '/' + id +'_minx%d_maxx%d_miny%d_maxy%d_minz%d_maxz%d'%(minx,maxx,miny,maxy,minz,maxz)+ \"_img.nii.gz\")\n",
    "    #             nib.save(nib.Nifti1Image(label_pred.astype(np.float32), np.eye(4)), \n",
    "    #                      out_dir+ '/' + id +'_minx%d_maxx%d_miny%d_maxy%d_minz%d_maxz%d'%(minx,maxx,miny,maxy,minz,maxz)+ \"_pred.nii.gz\")\n",
    "    #             nib.save(nib.Nifti1Image(label_onehot_pred[:].astype(np.float32), np.eye(4)), \n",
    "    #                      out_dir+ '/' + id +'_minx%d_maxx%d_miny%d_maxy%d_minz%d_maxz%d'%(minx,maxx,miny,maxy,minz,maxz)+ \"_label_onehot_pred.nii.gz\")\n",
    "        except:\n",
    "            print('skip case %s'%id)\n",
    "    print('All finished')\n",
    "\n",
    "\n",
    "# -\n",
    "\n",
    "from skimage import measure\n",
    "def filter_connected_domain(image,min_region_area=None,num_keep_region=None,ratio_keep=None):\n",
    "    \"\"\"\n",
    "    原文链接：https://blog.csdn.net/a563562675/article/details/107066836\n",
    "    return label of filter \n",
    "    \"\"\"\n",
    "    # 标记输入的3D图像\n",
    "    label, num = measure.label(image, connectivity=1, background=0, return_num=True)\n",
    "    if num < 1:\n",
    "        return image\n",
    "\n",
    "    # 获取对应的region对象\n",
    "    region = measure.regionprops(label)\n",
    "    # 获取每一块区域面积并排序\n",
    "    num_list = [i for i in range(0, num)]\n",
    "    area_list = [region[i].area for i in num_list]\n",
    "    \n",
    "    # 去除面积较小的连通域\n",
    "    if min_region_area:\n",
    "        drop_list = np.where(np.array(area_list)<min_region_area)[0]\n",
    "        for i in drop_list:\n",
    "            label[region[i].slice][region[i].image] = 0\n",
    "    elif ratio_keep:\n",
    "        max_region_area = np.array(area_list).max()\n",
    "        drop_list = np.where(np.array(area_list)<max_region_area*ratio_keep)[0]\n",
    "        for i in drop_list:\n",
    "            label[region[i].slice][region[i].image] = 0 \n",
    "    \n",
    "    else:\n",
    "        if len(num_list) > num_keep_region:\n",
    "            num_list_sorted = sorted(num_list, key=lambda x: area_list[x])[::-1]# 面积由大到小排序\n",
    "            for i in num_list_sorted[num_keep_region:]:\n",
    "                # label[label==i] = 0\n",
    "                label[region[i].slice][region[i].image] = 0\n",
    "#             num_list_sorted = num_list_sorted[:num_keep_region]\n",
    "    return label\n",
    "\n",
    "\n",
    "def test_all_case(\n",
    "    net, image_list, \n",
    "    num_classes, \n",
    "    name_classes,\n",
    "    patch_size=(112, 112, 80), stride_xy=18, stride_z=4, \n",
    "    save_result=True, test_save_path=None, preproc_fn=None,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    if num_classes==2:\n",
    "        cols = ['dice','jc','hd','asd']\n",
    "    else:\n",
    "        cols = [['dice']*len(name_classes)+['jc']*len(name_classes)+['hd']*len(name_classes)+['asd']*len(name_classes), name_classes*4]\n",
    "    metrics = pd.DataFrame(columns=cols) \n",
    "\n",
    "    for image_path in tqdm(image_list):\n",
    "        id = image_path.split('/')[-2]\n",
    "        h5f = h5py.File(image_path, 'r')\n",
    "        image = h5f['image'][:]\n",
    "        label = np.argmax(h5f['label'][:],axis=-1)\n",
    "        if preproc_fn is not None:\n",
    "            image = preproc_fn(image)\n",
    "        prediction, score_map = test_single_case(net, image, stride_xy, stride_z, patch_size, num_classes=num_classes, device=\"cuda\")\n",
    "\n",
    "        if np.sum(prediction)==0:\n",
    "            single_metric = (0,0,0,0)\n",
    "        else:\n",
    "            single_metric = calculate_metric_percase(prediction, label[:], num_classes)\n",
    "        \n",
    "        print(id,':')\n",
    "        print(\"single_metric:\",single_metric)\n",
    "\n",
    "        metrics.loc[id] = np.array(single_metric).flatten().tolist()\n",
    "        if save_result:\n",
    "            nib.save(nib.Nifti1Image(prediction.astype(np.float32), np.eye(4)), test_save_path + id + \"_pred.nii.gz\")\n",
    "            nib.save(nib.Nifti1Image(image[:].astype(np.float32), np.eye(4)), test_save_path + id + \"_img.nii.gz\")\n",
    "            nib.save(nib.Nifti1Image(label[:].astype(np.float32), np.eye(4)), test_save_path + id + \"_gt.nii.gz\")\n",
    "    mean_metrics = metrics.mean()\n",
    "    print('mean metric is:\\n')\n",
    "    print(mean_metrics)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def test_single_case(net, image, stride_xy, stride_z, patch_size, num_classes=1, device=\"cuda\"):\n",
    "    w, h, d = image.shape\n",
    "\n",
    "    # if the size of image is less than patch_size, then padding it\n",
    "    add_pad = False\n",
    "    if w < patch_size[0]:\n",
    "        w_pad = patch_size[0]-w\n",
    "        add_pad = True\n",
    "    else:\n",
    "        w_pad = 0\n",
    "    if h < patch_size[1]:\n",
    "        h_pad = patch_size[1]-h\n",
    "        add_pad = True\n",
    "    else:\n",
    "        h_pad = 0\n",
    "    if d < patch_size[2]:\n",
    "        d_pad = patch_size[2]-d\n",
    "        add_pad = True\n",
    "    else:\n",
    "        d_pad = 0\n",
    "    wl_pad, wr_pad = w_pad//2,w_pad-w_pad//2\n",
    "    hl_pad, hr_pad = h_pad//2,h_pad-h_pad//2\n",
    "    dl_pad, dr_pad = d_pad//2,d_pad-d_pad//2\n",
    "    if add_pad:\n",
    "        image = np.pad(image, [(wl_pad,wr_pad),(hl_pad,hr_pad), (dl_pad, dr_pad)], mode='constant', constant_values=0)\n",
    "    ww,hh,dd = image.shape\n",
    "\n",
    "    sx = math.ceil((ww - patch_size[0]) / stride_xy) + 1\n",
    "    sy = math.ceil((hh - patch_size[1]) / stride_xy) + 1\n",
    "    sz = math.ceil((dd - patch_size[2]) / stride_z) + 1\n",
    "    print(\"{}, {}, {}\".format(sx, sy, sz))\n",
    "    score_map = np.zeros((num_classes, ) + image.shape).astype(np.float32)\n",
    "    cnt = np.zeros(image.shape).astype(np.float32)\n",
    "\n",
    "    for x in range(0, sx):\n",
    "        xs = min(stride_xy*x, ww-patch_size[0])\n",
    "        for y in range(0, sy):\n",
    "            ys = min(stride_xy * y,hh-patch_size[1])\n",
    "            for z in range(0, sz):\n",
    "                zs = min(stride_z * z, dd-patch_size[2])\n",
    "                test_patch = image[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]]\n",
    "                test_patch = np.expand_dims(np.expand_dims(test_patch,axis=0),axis=0).astype(np.float32)\n",
    "                test_patch = torch.from_numpy(test_patch).to(device)# cpu\n",
    "                y1 = net(test_patch)\n",
    "                y = F.softmax(y1, dim=1)\n",
    "                y = y.cpu().data.numpy()\n",
    "                y = y[0,:,:,:,:]\n",
    "                score_map[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] += y\n",
    "                cnt[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] += 1\n",
    "    score_map = score_map/np.expand_dims(cnt,axis=0)\n",
    "    label_map = np.argmax(score_map, axis = 0)\n",
    "    if add_pad:\n",
    "        label_map = label_map[wl_pad:wl_pad+w,hl_pad:hl_pad+h,dl_pad:dl_pad+d]\n",
    "        score_map = score_map[:,wl_pad:wl_pad+w,hl_pad:hl_pad+h,dl_pad:dl_pad+d]\n",
    "    return label_map, score_map\n",
    "\n",
    "def cal_dice(prediction, label, num=2):\n",
    "    total_dice = np.zeros(num-1)\n",
    "    for i in range(1, num):\n",
    "        prediction_tmp = (prediction==i)\n",
    "        label_tmp = (label==i)\n",
    "        prediction_tmp = prediction_tmp.astype(np.float)\n",
    "        label_tmp = label_tmp.astype(np.float)\n",
    "\n",
    "        dice = 2 * np.sum(prediction_tmp * label_tmp) / (np.sum(prediction_tmp) + np.sum(label_tmp))\n",
    "        total_dice[i - 1] += dice\n",
    "\n",
    "    return total_dice\n",
    "\n",
    "def calculate_metric_percase(pred, gt, num_classes):\n",
    "    \"二分类、多分类的指标统计\"\n",
    "    if num_classes is None:\n",
    "        num_classes = len(np.unique(gt))#注意：gt不是onehot编码\n",
    "    print('np.unique(gt):',np.unique(gt))\n",
    "    if num_classes==2:\n",
    "        dice = metric.binary.dc(pred, gt)\n",
    "        jc = metric.binary.jc(pred, gt)\n",
    "        hd = metric.binary.hd95(pred, gt)\n",
    "        asd = metric.binary.asd(pred, gt)\n",
    "    elif num_classes>2:\n",
    "        from keras.utils import to_categorical\n",
    "        gt_onehot = to_categorical(gt, num_classes)\n",
    "        pred_onehot = to_categorical(pred, num_classes)\n",
    "        dice = []\n",
    "        jc = []\n",
    "        hd = []\n",
    "        asd = []\n",
    "        for k in range(num_classes):\n",
    "            pred_k = pred_onehot[...,k]\n",
    "            gt_k = gt_onehot[...,k]\n",
    "            dice +=  [metric.dc(result=pred_k, reference=gt_k)]\n",
    "            jc += [metric.jc(result=pred_k, reference=gt_k)]\n",
    "            hd += [metric.hd95(result=pred_k, reference=gt_k)]\n",
    "            asd += [metric.asd(result=pred_k, reference=gt_k)]\n",
    "    else:\n",
    "        raise ValueError(\"pred和gt不能是onehot编码\")\n",
    "    return dice, jc, hd, asd\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "a160173d-0779-4e0e-b3a1-e71798073f1c"
   },
   "outputs": [],
   "source": [
    "'minX%d_maxX%d_minY%d_maxY%d_minZ%d_maxZ%d'%(2,3,4,5,6,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "c1545857-965d-45f0-ba6e-089c90ab08e6"
   },
   "outputs": [],
   "source": [
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "a077bbad-4f53-4b9e-ad17-339280e2b4f9"
   },
   "outputs": [],
   "source": [
    "int('(0,1,2)')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "uuid": "eb319cba-d0df-404a-abe1-c7009202eaec"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "24b0f201-eddf-4359-8a74-b4399080499b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
