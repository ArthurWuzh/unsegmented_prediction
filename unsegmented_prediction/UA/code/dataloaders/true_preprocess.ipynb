{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "uuid": "4cd72851-0fab-4aa4-84df-60b097199ea3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=np.array([1,2,3])\n",
    "np.unique(a).tolist() == [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "uuid": "5eb303eb-6633-450a-bf61-fdd96cde1005"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import nrrd\n",
    "import os\n",
    "import pandas as pd\n",
    "from dataset_split import remove_files\n",
    "import SimpleITK as sitk\n",
    "from skimage import transform\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "uuid": "b026e59b-615a-459e-af95-f5a3e54bdb7b"
   },
   "outputs": [],
   "source": [
    "output_size =[128, 128, 64]\n",
    "old_space = []\n",
    "counter_label = []\n",
    "def resample_image3D(\n",
    "    image3D,\n",
    "    newspacing=[1.0,1.0,1.0],\n",
    "    newsize=None,\n",
    "    method='Linear',):\n",
    "    \"\"\"做插值\"\"\"\n",
    "    resample = sitk.ResampleImageFilter()\n",
    "    if method == 'Linear':\n",
    "        resample.SetInterpolator(sitk.sitkLinear)\n",
    "    elif method == 'Nearest':\n",
    "        resample.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "    resample.SetOutputDirection(image3D.GetDirection())\n",
    "    resample.SetOutputOrigin(image3D.GetOrigin())\n",
    "    resample.SetOutputSpacing(newspacing)\n",
    "\n",
    "    if not newsize:\n",
    "        newsize = np.round(np.array(image3D.GetSize())*np.abs(image3D.GetSpacing())/np.array(newspacing)).astype('int').tolist()\n",
    "\n",
    "    resample.SetSize(newsize)\n",
    "    # resample.SetDefaultPixelValue(0)\n",
    "\n",
    "    newimage = resample.Execute(image3D)\n",
    "    return newimage\n",
    "\n",
    "\n",
    "def sitk_onehot_transform(image):\n",
    "    image_array = sitk.GetArrayFromImage(image)\n",
    "    label_array_onehot = to_categorical(image_array)\n",
    "    image_onehot = sitk.GetImageFromArray(label_array_onehot)\n",
    "    image_onehot.SetOrigin(image.GetOrigin())\n",
    "    image_onehot.SetDirection(image.GetDirection())\n",
    "    image_onehot.SetSpacing(image.GetSpacing())\n",
    "    return image_onehot\n",
    "\n",
    "# 数组替换元素\n",
    "def array_replace(array,olds,news):\n",
    "    # 不适用于onehot\n",
    "    #olds:list of old value\n",
    "    #news:list of new value\n",
    "    olds = np.array(olds)\n",
    "    news = np.array(news)\n",
    "    offset = olds.max()*10\n",
    "    tmps = olds+offset\n",
    "    array += offset\n",
    "    for tmp,new in zip(tmps,news):\n",
    "        array[array==tmp] = new\n",
    "    return array\n",
    "\n",
    "\n",
    "def make_out_itk(image,image_sitk):\n",
    "    out_image_sitk = sitk.GetImageFromArray(image)\n",
    "    out_image_sitk.SetSpacing(image_sitk.GetSpacing())\n",
    "    out_image_sitk.SetOrigin(image_sitk.GetOrigin())\n",
    "    out_image_sitk.SetDirection(image_sitk.GetDirection())\n",
    "    return out_image_sitk\n",
    "\n",
    "def covert_h5(glob_str, old_replaced, new_replaced):\n",
    "    \"\"\"\n",
    "    备注：不要骨头，骨头合并到背景类别中\n",
    "    \"\"\"\n",
    "    listt = glob(glob_str)\n",
    "    error_samples = []\n",
    "    error_samples_origin = []\n",
    "    '''stats = pd.DataFrame(columns=['sample_name',\n",
    "                                  'mean_whole', \n",
    "                                  'mean_bg', \n",
    "                                  'mean_dura', \n",
    "                                  'mean_SC', \n",
    "                                  'std_whole',\n",
    "                                  'std_bg',\n",
    "                                  'std_dura',\n",
    "                                  'std_SC',\n",
    "                                  'old_space0','old_space1','old_space2',\n",
    "                                  'new_space0','new_space1','new_space2',\n",
    "                                 ])'''\n",
    "    for item in tqdm(listt):\n",
    "        sample_name = item.split('/')[-2]\n",
    "        print(sample_name,':')#win系统改为'\\\\'\n",
    "#         if not sample_name == \"1171704-neck\":#B809338\":#\"\"1352900\":#B809338\":#\"1756747\":#1700637-neck\":\n",
    "#             continue\n",
    "        \n",
    "        # read image\n",
    "        print(\"item: \",item)\n",
    "        image = sitk.ReadImage(item)\n",
    "        seg = sitk.ReadImage(item.replace(old_replaced, 'Segmentation.seg.nrrd'))\n",
    "        label = sitk.ReadImage(item.replace(old_replaced, 'Segmentation-label.nrrd'))\n",
    "        label_onehot = sitk_onehot_transform(label)\n",
    "        \n",
    "        \n",
    "        label_name = [\n",
    "            'bg',\n",
    "            seg.GetMetaData('Segment0_Name'),\n",
    "            seg.GetMetaData('Segment1_Name'),\n",
    "            seg.GetMetaData('Segment2_Name') \n",
    "            ]#人工标注的类别顺序\n",
    "        oldspacing = np.abs(image.GetSpacing())\n",
    "        old_space.append(oldspacing)\n",
    "        print('oldspacing: ',oldspacing)\n",
    "        newspacing = [1.0, 1.0, 1.0]\n",
    "\n",
    "        # resample/rescale( by sitk )\n",
    "        image = resample_image3D(image,newspacing,method='Linear')\n",
    "        label_onehot = resample_image3D(label_onehot,newspacing,method='Nearest')\n",
    "        \n",
    "        # get array\n",
    "        image = sitk.GetArrayFromImage(image).transpose((2,1,0))#tanspose之后才能与sizes匹配\n",
    "        label_onehot = np.round( sitk.GetArrayFromImage(label_onehot) ).transpose((2,1,0,3))#tanspose之后才能与sizes匹配\n",
    "        label = np.argmax(label_onehot,axis=-1)\n",
    "        #label_temp = label.flatten()\n",
    "        #print(Counter(label_temp))\n",
    "        #plot_slice_sample(image,label,np.nonzero(label)[2].max(),item.replace(old_replaced,'slice_sample_origin.png'))\n",
    "        \n",
    "        \n",
    "        if not image.shape == label_onehot.shape[:-1]:\n",
    "            error_samples.append(sample_name)\n",
    "            print(\"error sample(mismatch shape of image and label):\",sample_name)\n",
    "            continue\n",
    "\n",
    "        if not label_onehot.sum(axis=-1).max()==1:\n",
    "            # label onehot encoder可以解决这个问题\n",
    "            error_samples.append(sample_name)\n",
    "            print(\"error sample(some pixels in seg are multi-category at the same time):\",sample_name)\n",
    "            continue\n",
    "        \n",
    "        # 灰度标准化\n",
    "        image = (image - np.mean(image)) / np.std(image)\n",
    "        image = image.astype(np.float32)\n",
    "\n",
    "        \n",
    "        # 错误病例：标记的尺寸和image尺寸不同，缺少其中一个类别或者多个类别的标记\n",
    "        if not label_onehot.shape[-1] == 4:\n",
    "            error_samples.append(sample_name)\n",
    "            print(\"error sample(no df/pf/fra):\",sample_name)\n",
    "            continue \n",
    "        if not (np.unique(label_onehot) == [0, 1]).all():\n",
    "            error_samples.append(sample_name)\n",
    "            print(\"error sample label file error:\",sample_name)   \n",
    "            continue\n",
    "        \n",
    "        ## 调整类别顺序&合并骨头到背景中，注意：是onehot编码\n",
    "        target_name = ['bg','proximal femur','distal femur','fragment']#目标类别顺序\n",
    "        idx = [label_name.index(name) for name in target_name]\n",
    "        assert len(idx)==4,'one or more classes missed'\n",
    "        label_onehot = label_onehot[:,:,:,idx]\n",
    "\n",
    "        '''## bone归入背景类\n",
    "        bg = label_onehot[:,:,:,[0,1]].sum(axis=-1)[:,:,:,np.newaxis]\n",
    "        label_onehot = np.concatenate((bg,label_onehot[:,:,:,2:]),axis=-1)\n",
    "        assert (np.unique(label_onehot) == [0, 1]).all(), \"1: pixel class error\"\n",
    "        ## 转化为非onehot编码以便作图'''\n",
    "        label = np.argmax(label_onehot, axis=-1)\n",
    "        \n",
    "        # cut( random center cut)\n",
    "        tempL = np.nonzero(label)\n",
    "        minx, maxx = np.min(tempL[0]), np.max(tempL[0])\n",
    "        miny, maxy = np.min(tempL[1]), np.max(tempL[1])\n",
    "        minz, maxz = np.min(tempL[2]), np.max(tempL[2])\n",
    "        w, h, d = label.shape\n",
    "        px = max(output_size[0] - (maxx-minx+1), 0) // 2\n",
    "        py = max(output_size[1] - (maxy-miny+1), 0) // 2\n",
    "        #pz = max(output_size[2] - (maxz-minz+1), 0) // 2\n",
    "        minx = max(minx - np.random.randint(10, 20) - px, 0)\n",
    "        maxx = min(maxx + np.random.randint(10, 20) + px, w-1)\n",
    "        miny = max(miny - np.random.randint(10, 20) - py, 0)\n",
    "        maxy = min(maxy + np.random.randint(10, 20) + py, h-1)\n",
    "        #minz = max(minz - np.random.randint(10, 20) - pz, 0)\n",
    "        #maxz = min(maxz + np.random.randint(10, 20) + pz, d)\n",
    "        image = image[minx:maxx+1, miny:maxy+1, minz:maxz+1]\n",
    "        label = label[minx:maxx+1, miny:maxy+1, minz:maxz+1]\n",
    "        label_onehot = label_onehot[minx:maxx+1, miny:maxy+1, minz:maxz+1, :]\n",
    "        print(\"cut image.shape:\",image.shape, \"cut label.shape:\",label.shape)\n",
    "        #plot_slice_sample(image,label,maxz-minz,item.replace(old_replaced,'slice_sample.png'))\n",
    "        print(\"minx: \",minx, \"maxx: \",maxx)\n",
    "        print(\"index: \",int((maxx-minx)/2))\n",
    "        #plot_slice_sample(image,label,int((maxx-minx)/2),item.replace(old_replaced,'slice_sample.png'))\n",
    "        \n",
    "        # save files\n",
    "        f = h5py.File(item.replace(old_replaced, new_replaced), 'w')\n",
    "        f.create_dataset('image', data=image, compression=\"gzip\")\n",
    "        f.create_dataset('label', data=label_onehot, compression=\"gzip\")\n",
    "        f.close()\n",
    "    print(\"total number of samples:\", len(listt))\n",
    "    return error_samples, error_samples_origin\n",
    "\n",
    "def plot_slice_sample(image,label,d,fn):\n",
    "    fig = plt.figure()\n",
    "    a = fig.add_subplot(1, 2, 1)\n",
    "    imgplot = plt.imshow(image[d,:,:].squeeze())\n",
    "    a.set_title('image')\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "    a = fig.add_subplot(1, 2, 2)\n",
    "    imgplot = plt.imshow(label[d,:,:].squeeze())\n",
    "    imgplot.set_clim(0.0, 3.0)\n",
    "    a.set_title('label')\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "    plt.savefig(fn)\n",
    "    plt.show()\n",
    "    \n",
    "def covert_h5_unseg(glob_str, old_replaced, new_replaced):\n",
    "    \"\"\"\n",
    "    备注：无标注数据的格式转换\n",
    "    \"\"\"\n",
    "    listt = glob(glob_str)\n",
    "    for item in tqdm(listt):\n",
    "        sample_name = item.split('/')[-2]\n",
    "        print(\"item: \", item)\n",
    "        print(\"sample_name: \",sample_name)\n",
    "        print(sample_name,':')#win系统改为'\\\\'\n",
    "        \n",
    "        image = sitk.ReadImage(item)\n",
    "        \n",
    "        # resample\n",
    "        newspacing = [1.0, 1.0, 1.0]\n",
    "        image = resample_image3D(image,newspacing,method='Linear')\n",
    "        image = sitk.GetArrayFromImage(image).transpose((2,1,0))#tanspose之后才能与sizes匹配\n",
    "        \n",
    "        # 灰度标准化\n",
    "        image = (image - np.mean(image)) / np.std(image)\n",
    "        image = image.astype(np.float32)\n",
    "        print(\"image shape:\",image.shape)\n",
    "        \n",
    "        f = h5py.File(item.replace(old_replaced, new_replaced), 'w')\n",
    "        f.create_dataset('image', data=image, compression=\"gzip\")\n",
    "        f.close() \n",
    "    print(\"total number of unseg-samples:\", len(listt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "uuid": "93943415-79d1-4cd8-9645-8ceede185d77"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seg dataset:\n",
      "112241 :\n",
      "item:  ../../../data/gz_dataset/segmented/112241/CT.nrrd\n",
      "oldspacing:  [0.782 0.782 1.   ]\n",
      "cut image.shape: (158, 156, 106) cut label.shape: (158, 156, 106)\n",
      "minx:  153 maxx:  310\n",
      "index:  78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█▍        | 1/7 [00:32<03:17, 32.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135535 :\n",
      "item:  ../../../data/gz_dataset/segmented/135535/CT.nrrd\n",
      "oldspacing:  [0.503 0.503 1.   ]\n",
      "cut image.shape: (162, 157, 118) cut label.shape: (162, 157, 118)\n",
      "minx:  66 maxx:  227\n",
      "index:  80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|██▊       | 2/7 [00:52<02:24, 28.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145101 :\n",
      "item:  ../../../data/gz_dataset/segmented/145101/CT.nrrd\n",
      "oldspacing:  [0.496 0.496 1.   ]\n",
      "cut image.shape: (152, 150, 189) cut label.shape: (152, 150, 189)\n",
      "minx:  42 maxx:  193\n",
      "index:  75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████▎     | 3/7 [01:11<01:43, 25.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151000 :\n",
      "item:  ../../../data/gz_dataset/segmented/151000/CT.nrrd\n",
      "oldspacing:  [0.454 0.454 0.8  ]\n",
      "cut image.shape: (152, 153, 93) cut label.shape: (152, 153, 93)\n",
      "minx:  0 maxx:  151\n",
      "index:  75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████▋    | 4/7 [01:27<01:09, 23.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190409 :\n",
      "item:  ../../../data/gz_dataset/segmented/190409/CT.nrrd\n",
      "oldspacing:  [0.393 0.393 0.8  ]\n",
      "cut image.shape: (164, 155, 143) cut label.shape: (164, 155, 143)\n",
      "minx:  5 maxx:  168\n",
      "index:  81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████▏  | 5/7 [01:45<00:43, 21.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200617 :\n",
      "item:  ../../../data/gz_dataset/segmented/200617/CT.nrrd\n",
      "oldspacing:  [0.515 0.515 1.   ]\n",
      "cut image.shape: (154, 164, 113) cut label.shape: (154, 164, 113)\n",
      "minx:  63 maxx:  216\n",
      "index:  76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████▌ | 6/7 [02:05<00:20, 20.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223849 :\n",
      "item:  ../../../data/gz_dataset/segmented/223849/CT.nrrd\n",
      "oldspacing:  [0.545 0.545 1.   ]\n",
      "cut image.shape: (159, 160, 106) cut label.shape: (159, 160, 106)\n",
      "minx:  77 maxx:  235\n",
      "index:  79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 7/7 [02:16<00:00, 19.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of samples: 7\n",
      "[0.52685714 0.52685714 0.94285714]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('seg dataset:')\n",
    "## 先删除旧文件\n",
    "dataset_dir = '../../../data/gz_dataset/segmented'\n",
    "re = os.path.join(dataset_dir,'*/mri_norm2.h5')\n",
    "remove_files(re=re)\n",
    "## 再生成新文件\n",
    "glob_str = '../../../data/gz_dataset/segmented/*/CT.nrrd'\n",
    "error_samples,error_samples_origin = covert_h5(glob_str,'CT.nrrd','mri_norm2.h5')\n",
    "old_space=np.array(old_space)\n",
    "print(old_space.mean(axis=0))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "uuid": "a07721c4-bcd0-4cf3-9913-98988b865894"
   },
   "outputs": [],
   "source": [
    "from dataset_split import dataset_split, make_dataset_list\n",
    "# 有标签数据(划分为两个数据集并生成列表)\n",
    "save_dir = '../../../data/gz_dataset'\n",
    "dataset_dir = '../../../data/gz_dataset/segmented'\n",
    "list_train_validatioin,list_test = dataset_split(path=dataset_dir,save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "uuid": "99fe6cc0-a5be-43f9-badc-a3a4425cfb27"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "uuid": "a47cf7c9-30c0-4362-91f3-a21a0e7b6c61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ceil(1.63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "e7698b8b-cad3-41eb-8608-dd17dd37aae2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
