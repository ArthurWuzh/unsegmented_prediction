{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "uuid": "13054749-a5e8-43d2-9a49-c0cbd8a10379"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from networks.vnet import VNet\n",
    "#from test_util import test_all_case\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "uuid": "7e6fa584-a41a-4ed6-a0ca-ad75117c4621"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# +\n",
    "import h5py\n",
    "import math\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from medpy import metric\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "\n",
    "def predict_and_center_cut_all_case(net, image_list, num_classes, \n",
    "                        patch_size=(112, 112, 80), stride_xy=18, stride_z=4, \n",
    "                        save_result=True, test_save_path=None, preproc_fn=None,\n",
    "                        device='cpu'):\n",
    "    for image_path in tqdm(image_list):\n",
    "        id = image_path.split('/')[-2]\n",
    "        print(id,':')\n",
    "        out_dir = test_save_path+id\n",
    "        if not os.path.isdir(out_dir):\n",
    "            os.mkdir(out_dir)\n",
    "            \n",
    "        h5f = h5py.File(image_path, 'r')\n",
    "        image = h5f['image'][:]\n",
    "        if preproc_fn is not None:\n",
    "            image = preproc_fn(image)\n",
    "        label_pred, score_map = test_single_case(\n",
    "            net, image, \n",
    "            stride_xy, stride_z, patch_size, \n",
    "            num_classes=num_classes, \n",
    "            device=device)\n",
    "        \n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "        filter_mask = filter_connected_domain(label_pred,num_keep_region=None,ratio_keep=0.001)\n",
    "        filter_mask = (filter_mask>0).astype(float)\n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "        label_pred = label_pred*filter_mask\n",
    "\n",
    "        # 发现圆形视场的边界处经常出现错误分割(轮廓线),因此需要手动过滤\n",
    "        r = label_pred.shape[0]/2\n",
    "        xc,yc = label_pred.shape[0]/2,label_pred.shape[0]/2\n",
    "#         filter_mask = np.ones(label_pred.shape)\n",
    "#         for x in range(label_pred.shape[0]):\n",
    "#             for y in range(label_pred.shape[1]):\n",
    "#                 filter_mask[x,y,:] = 0 if r*0.5<np.sqrt((x-xc)**2+(y-yc)**2)<r*2 else 1\n",
    "#         label_pred = filter_mask*label_pred\n",
    "        \n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "        # onehot\n",
    "        label_onehot_pred = tf.keras.utils.to_categorical(label_pred)\n",
    "        if not label_onehot_pred.shape[-1]==3:\n",
    "            print(id+' onehot shape error: miss one or more pixel class')\n",
    "            continue\n",
    "            \n",
    "        # center cut\n",
    "        tempL = np.nonzero(label_pred)\n",
    "        minx, maxx = np.min(tempL[0]).astype(int), np.max(tempL[0]).astype(int)\n",
    "        miny, maxy = np.min(tempL[1]).astype(int), np.max(tempL[1]).astype(int)\n",
    "        minz, maxz = np.min(tempL[2]).astype(int), np.max(tempL[2]).astype(int)\n",
    "        image = image[minx:maxx+1, miny:maxy+1, minz:maxz+1]\n",
    "        label_pred = label_pred[minx:maxx+1, miny:maxy+1, minz:maxz+1]\n",
    "        label_onehot_pred = label_onehot_pred[minx:maxx+1, miny:maxy+1, minz:maxz+1, :]\n",
    "            \n",
    "        # case 拼接\n",
    "        numd = []\n",
    "        for d in range(label_pred.shape[2]):\n",
    "            numd.append( len(np.where(label_pred[:,:,d].flatten()==2)[0]) )\n",
    "        numd = np.array(numd)\n",
    "        slice = int(np.where(numd==numd.max())[0][0])\n",
    "        fig = plt.figure( frameon=False)#dpi=100, \n",
    "        image_unstd = (image-image.min())/(image.max()-image.min())*255\n",
    "        npimg = np.append( image_unstd[:,:,slice],label_pred[:,:,slice]/2*255,axis=1 )\n",
    "        plt.imshow(npimg.astype(int),cmap='plasma')#一定要转为int\n",
    "        plt.savefig( test_save_path + id + str(slice) + \"_pred.png\" )\n",
    "        plt.show()\n",
    "        \n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "        \n",
    "        if save_result:\n",
    "            # save files\n",
    "            filename = os.path.join(os.path.dirname(image_path),'center_cut.h5')\n",
    "            f = h5py.File(filename, 'w')\n",
    "            f.create_dataset('image', data=image.astype(np.float32), compression=\"gzip\")\n",
    "#             f.create_dataset('label', data=label_onehot_pred.astype(np.int), compression=\"gzip\")\n",
    "            f.close()\n",
    "#             nib.save(nib.Nifti1Image(image[:].astype(np.float32), np.eye(4)), \n",
    "#                      out_dir+ '/' + id +'_minx%d_maxx%d_miny%d_maxy%d_minz%d_maxz%d'%(minx,maxx,miny,maxy,minz,maxz)+ \"_img.nii.gz\")\n",
    "#             nib.save(nib.Nifti1Image(label_pred.astype(np.float32), np.eye(4)), \n",
    "#                      out_dir+ '/' + id +'_minx%d_maxx%d_miny%d_maxy%d_minz%d_maxz%d'%(minx,maxx,miny,maxy,minz,maxz)+ \"_pred.nii.gz\")\n",
    "#             nib.save(nib.Nifti1Image(label_onehot_pred[:].astype(np.float32), np.eye(4)), \n",
    "#                      out_dir+ '/' + id +'_minx%d_maxx%d_miny%d_maxy%d_minz%d_maxz%d'%(minx,maxx,miny,maxy,minz,maxz)+ \"_label_onehot_pred.nii.gz\")\n",
    "    print('All finished')\n",
    "\n",
    "\n",
    "# -\n",
    "\n",
    "from skimage import measure\n",
    "def filter_connected_domain(image,num_keep_region=100,ratio_keep=None):\n",
    "    \"\"\"\n",
    "    原文链接：https://blog.csdn.net/a563562675/article/details/107066836\n",
    "    return label of filter \n",
    "    \"\"\"\n",
    "    # 标记输入的3D图像\n",
    "    label, num = measure.label(image, connectivity=1, background=0, return_num=True)\n",
    "    if num < 1:\n",
    "        return image\n",
    "\n",
    "    # 获取对应的region对象\n",
    "    region = measure.regionprops(label)\n",
    "    # 获取每一块区域面积并排序\n",
    "    num_list = [i for i in range(0, num)]\n",
    "    area_list = [region[i].area for i in num_list]\n",
    "    \n",
    "    # 去除面积较小的连通域\n",
    "    if ratio_keep:\n",
    "        max_region_area = np.array(area_list).max()\n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "        drop_list = np.where(area_list<max_region_area*ratio_keep)[0]\n",
    "        for i in drop_list:\n",
    "            label[region[i].slice][region[i].image] = 0 \n",
    "    \n",
    "    else:\n",
    "        if len(num_list) > num_keep_region:\n",
    "            num_list_sorted = sorted(num_list, key=lambda x: area_list[x])[::-1]# 面积由大到小排序\n",
    "            for i in num_list_sorted[num_keep_region:]:\n",
    "                # label[label==i] = 0\n",
    "                label[region[i].slice][region[i].image] = 0\n",
    "#             num_list_sorted = num_list_sorted[:num_keep_region]\n",
    "    import pdb\n",
    "    pdb.set_trace()\n",
    "    return label\n",
    "\n",
    "\n",
    "def test_all_case(\n",
    "    net, image_list, \n",
    "    num_classes, \n",
    "    name_classes,\n",
    "    patch_size=(112, 112, 80), stride_xy=18, stride_z=4, \n",
    "    save_result=True, test_save_path=None, preproc_fn=None,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    '''if num_classes==2:\n",
    "        cols = ['dice','jc','hd','asd']\n",
    "    else:\n",
    "        cols = [['dice']*len(name_classes)+['jc']*len(name_classes)+['hd']*len(name_classes)+['asd']*len(name_classes), name_classes*4]\n",
    "    metrics = pd.DataFrame(columns=cols) '''\n",
    "    metrics = pd.DataFrame(columns=['bg','proximal_femur','distal_femur','fragment']) \n",
    "    for image_path in tqdm(image_list):\n",
    "        id = image_path.split('/')[-2]\n",
    "        h5f = h5py.File(image_path, 'r')\n",
    "        image = h5f['image'][:]\n",
    "        label = np.argmax(h5f['label'][:],axis=-1)\n",
    "        if preproc_fn is not None:\n",
    "            image = preproc_fn(image)\n",
    "        prediction, score_map = test_single_case(net, image, stride_xy, stride_z, patch_size, num_classes=num_classes, device=\"cuda\")\n",
    "\n",
    "        if np.sum(prediction)==0:\n",
    "            single_metric = (0,0,0,0)\n",
    "        else:\n",
    "            single_metric = calculate_metric_percase(prediction, label[:], num_classes)\n",
    "        \n",
    "        print(id,':')\n",
    "        print(\"single_metric:\",single_metric)\n",
    "\n",
    "        metrics.loc[id] = single_metric\n",
    "        if save_result:\n",
    "            nib.save(nib.Nifti1Image(prediction.astype(np.float32), np.eye(4)), test_save_path + id + \"_pred.nii.gz\")\n",
    "            nib.save(nib.Nifti1Image(image[:].astype(np.float32), np.eye(4)), test_save_path + id + \"_img.nii.gz\")\n",
    "            nib.save(nib.Nifti1Image(label[:].astype(np.float32), np.eye(4)), test_save_path + id + \"_gt.nii.gz\")\n",
    "    mean_metrics = metrics.mean()\n",
    "    print('mean metric is:\\n')\n",
    "    print(mean_metrics)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def test_single_case(net, image, stride_xy, stride_z, patch_size, num_classes=1, device=\"cuda\"):\n",
    "    w, h, d = image.shape\n",
    "\n",
    "    # if the size of image is less than patch_size, then padding it\n",
    "    add_pad = False\n",
    "    if w < patch_size[0]:\n",
    "        w_pad = patch_size[0]-w\n",
    "        add_pad = True\n",
    "    else:\n",
    "        w_pad = 0\n",
    "    if h < patch_size[1]:\n",
    "        h_pad = patch_size[1]-h\n",
    "        add_pad = True\n",
    "    else:\n",
    "        h_pad = 0\n",
    "    if d < patch_size[2]:\n",
    "        d_pad = patch_size[2]-d\n",
    "        add_pad = True\n",
    "    else:\n",
    "        d_pad = 0\n",
    "    wl_pad, wr_pad = w_pad//2,w_pad-w_pad//2\n",
    "    hl_pad, hr_pad = h_pad//2,h_pad-h_pad//2\n",
    "    dl_pad, dr_pad = d_pad//2,d_pad-d_pad//2\n",
    "    if add_pad:\n",
    "        image = np.pad(image, [(wl_pad,wr_pad),(hl_pad,hr_pad), (dl_pad, dr_pad)], mode='constant', constant_values=0)\n",
    "    ww,hh,dd = image.shape\n",
    "\n",
    "    sx = math.ceil((ww - patch_size[0]) / stride_xy) + 1\n",
    "    sy = math.ceil((hh - patch_size[1]) / stride_xy) + 1\n",
    "    sz = math.ceil((dd - patch_size[2]) / stride_z) + 1\n",
    "    print(\"{}, {}, {}\".format(sx, sy, sz))\n",
    "    score_map = np.zeros((num_classes, ) + image.shape).astype(np.float32)\n",
    "    cnt = np.zeros(image.shape).astype(np.float32)\n",
    "\n",
    "    for x in range(0, sx):\n",
    "        xs = min(stride_xy*x, ww-patch_size[0])\n",
    "        for y in range(0, sy):\n",
    "            ys = min(stride_xy * y,hh-patch_size[1])\n",
    "            for z in range(0, sz):\n",
    "                zs = min(stride_z * z, dd-patch_size[2])\n",
    "                test_patch = image[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]]\n",
    "                test_patch = np.expand_dims(np.expand_dims(test_patch,axis=0),axis=0).astype(np.float32)\n",
    "                #test_patch = torch.from_numpy(test_patch).cuda()# gpu\n",
    "                test_patch = torch.from_numpy(test_patch).to(device)# cpu\n",
    "                y1 = net(test_patch)\n",
    "                y = F.softmax(y1, dim=1)\n",
    "                y = y.cpu().data.numpy()\n",
    "                y = y[0,:,:,:,:]\n",
    "                score_map[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] += y\n",
    "                cnt[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] += 1\n",
    "    score_map = score_map/np.expand_dims(cnt,axis=0)\n",
    "    label_map = np.argmax(score_map, axis = 0)\n",
    "    if add_pad:\n",
    "        label_map = label_map[wl_pad:wl_pad+w,hl_pad:hl_pad+h,dl_pad:dl_pad+d]\n",
    "        score_map = score_map[:,wl_pad:wl_pad+w,hl_pad:hl_pad+h,dl_pad:dl_pad+d]\n",
    "    return label_map, score_map\n",
    "\n",
    "def cal_dice(prediction, label, num=2):\n",
    "    total_dice = np.zeros(num-1)\n",
    "    for i in range(1, num):\n",
    "        prediction_tmp = (prediction==i)\n",
    "        label_tmp = (label==i)\n",
    "        prediction_tmp = prediction_tmp.astype(np.float)\n",
    "        label_tmp = label_tmp.astype(np.float)\n",
    "\n",
    "        dice = 2 * np.sum(prediction_tmp * label_tmp) / (np.sum(prediction_tmp) + np.sum(label_tmp))\n",
    "        total_dice[i - 1] += dice\n",
    "\n",
    "    return total_dice\n",
    "\n",
    "def calculate_metric_percase(pred, gt, num_classes):\n",
    "    \"二分类、多分类的指标统计\"\n",
    "    if num_classes is None:\n",
    "        num_classes = len(np.unique(gt))#注意：gt不是onehot编码\n",
    "    print('np.unique(gt):',np.unique(gt))\n",
    "    if num_classes==2:\n",
    "        dice = metric.binary.dc(pred, gt)\n",
    "        jc = metric.binary.jc(pred, gt)\n",
    "        hd = metric.binary.hd95(pred, gt)\n",
    "        asd = metric.binary.asd(pred, gt)\n",
    "    elif num_classes>2:\n",
    "        from keras.utils import to_categorical\n",
    "        gt_onehot = to_categorical(gt, num_classes)\n",
    "        pred_onehot = to_categorical(pred, num_classes)\n",
    "        dice = []\n",
    "        jc = []\n",
    "        hd = []\n",
    "        asd = []\n",
    "        for k in range(num_classes):\n",
    "            pred_k = pred_onehot[...,k]\n",
    "            gt_k = gt_onehot[...,k]\n",
    "            dice +=  [metric.dc(result=pred_k, reference=gt_k)]\n",
    "            #jc += [metric.jc(result=pred_k, reference=gt_k)]\n",
    "            #hd += [metric.hd95(result=pred_k, reference=gt_k)]\n",
    "            #asd += [metric.asd(result=pred_k, reference=gt_k)]\n",
    "    else:\n",
    "        raise ValueError(\"pred和gt不能是onehot编码\")\n",
    "    return dice#, jc, hd, asd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "uuid": "3818fd67-82df-43d3-ad18-7f5f2bf71340"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--root_path', type=str, default='../../data/gz_dataset/segmented', help='Folder of Test Set')\n",
    "parser.add_argument('--model', type=str,  default='UAMT_unlabel', help='model_name')\n",
    "parser.add_argument('--gpu', type=str,  default='0', help='GPU to use')\n",
    "FLAGS = parser.parse_args(args=[])\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = FLAGS.gpu\n",
    "snapshot_path = \"../model/\"+FLAGS.model+\"/\"\n",
    "test_save_path = \"../model/prediction/\"+FLAGS.model+\"_post/\"\n",
    "if not os.path.exists(test_save_path):\n",
    "    os.makedirs(test_save_path)\n",
    "\n",
    "name_classes = ['bg','proximal_femur','distal_femur','fragment']\n",
    "num_classes = len(name_classes)\n",
    "\n",
    "with open(FLAGS.root_path + '/../test.list', 'r') as f:\n",
    "    image_list = f.readlines()\n",
    "image_list = [os.path.join(FLAGS.root_path,item.replace('\\n', ''),\"mri_norm2.h5\") for item in image_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "uuid": "9a6d1309-3a36-4f4d-8f1a-ca93823412b1"
   },
   "outputs": [],
   "source": [
    "def test_calculate_metric(epoch_num, patch_size=(128, 128, 64), stride_xy=64, stride_z=32, device='cuda'):\n",
    "    net = VNet(n_channels=1, n_classes=num_classes, normalization='batchnorm', has_dropout=False).to(device)#cuda()\n",
    "    save_mode_path = os.path.join(snapshot_path, 'iter_' + str(epoch_num) + '.pth')\n",
    "    net.load_state_dict(torch.load(save_mode_path))\n",
    "    print(\"init weight from {}\".format(save_mode_path))\n",
    "    net.eval()\n",
    "\n",
    "    metrics = test_all_case(\n",
    "        net, image_list, \n",
    "        num_classes=num_classes, \n",
    "        name_classes = name_classes,\n",
    "        patch_size=patch_size, stride_xy=stride_xy, stride_z=stride_z,\n",
    "        save_result=True, test_save_path=test_save_path)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "uuid": "cac3d730-69e8-4057-b8fd-1edf9baceae2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init weight from ../model/UAMT_unlabel/iter_6000.pth\n",
      "2, 2, 5\n",
      "np.unique(gt): [0 1 2 3]\n",
      "100207091 :\n",
      "single_metric: [0.9840534871916462, 0.42311079193276735, 0.7428261359792536, 0.34904364979596575]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▎        | 1/8 [00:03<00:23,  3.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2, 2, 3\n",
      "np.unique(gt): [0 1 2 3]\n",
      "100301649 :\n",
      "single_metric: [0.9747499795494395, 0.0004550763769852707, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 2/8 [00:05<00:17,  2.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2, 2, 3\n",
      "np.unique(gt): [0 1 2 3]\n",
      "100658440 :\n",
      "single_metric: [0.9834862215577133, 0.004364796239560163, 0.8013205887865288, 0.12948755778499066]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 3/8 [00:07<00:13,  2.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2, 2, 3\n",
      "np.unique(gt): [0 1 2 3]\n",
      "100752370 :\n",
      "single_metric: [0.9839010693421774, 0.21049578653948406, 0.682539005276557, 0.377642321887932]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 4/8 [00:09<00:10,  2.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2, 2, 3\n",
      "np.unique(gt): [0 1 2 3]\n",
      "100903938 :\n",
      "single_metric: [0.9764203051881838, 3.526155256615949e-05, 0.0, 0.008214079445549638]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|██████▎   | 5/8 [00:11<00:07,  2.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2, 2, 4\n",
      "np.unique(gt): [0 1 2 3]\n",
      "100067245 :\n",
      "single_metric: [0.9796683657435982, 0.0626012159184432, 0.5726238250854241, 0.24500078727759408]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:14<00:04,  2.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2, 2, 2\n",
      "np.unique(gt): [0 1 2 3]\n",
      "100218737 :\n",
      "single_metric: [0.9781352259175314, 0.33376588946097924, 0.28722877716219886, 0.2259190798932019]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|████████▊ | 7/8 [00:15<00:02,  2.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2, 2, 3\n",
      "np.unique(gt): [0 1 2 3]\n",
      "100201344 :\n",
      "single_metric: [0.9725220140734864, 0.0, 0.0018337545005255272, 0.039909706546275396]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 8/8 [00:18<00:00,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean metric is:\n",
      "\n",
      "bg                0.979117\n",
      "proximal_femur    0.129354\n",
      "distal_femur      0.386047\n",
      "fragment          0.171902\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    metrics = test_calculate_metric(6000, patch_size=(128, 128, 64), stride_xy=64, stride_z=32, device=device)\n",
    "    metrics.to_csv(os.path.join(test_save_path,'metrics_test_set.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "ba7b9cd0-2853-44c0-b477-633d08e30411"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
