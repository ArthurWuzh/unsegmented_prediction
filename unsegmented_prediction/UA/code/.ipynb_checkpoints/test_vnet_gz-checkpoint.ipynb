{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "uuid": "6a5ff4b4-2fd8-4bed-ae81-1d7fe8b6c89f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from networks.vnet import VNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "uuid": "f8d4d9da-ef2e-460c-b9d7-3c350311108b"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import math\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from medpy import metric\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "\n",
    "def predict_and_center_cut_all_case(net, image_list, num_classes, \n",
    "                        patch_size=(112, 112, 80), stride_xy=18, stride_z=4, \n",
    "                        save_result=True, test_save_path=None, preproc_fn=None,\n",
    "                        device='cpu'):\n",
    "    for image_path in tqdm(image_list):\n",
    "        id = image_path.split('/')[-2]\n",
    "        print(id,':')\n",
    "        out_dir = test_save_path+id\n",
    "        if not os.path.isdir(out_dir):\n",
    "            os.mkdir(out_dir)\n",
    "            \n",
    "        h5f = h5py.File(image_path, 'r')\n",
    "        image = h5f['image'][:]\n",
    "        if preproc_fn is not None:\n",
    "            image = preproc_fn(image)\n",
    "        label_pred, score_map = test_single_case(\n",
    "            net, image, \n",
    "            stride_xy, stride_z, patch_size, \n",
    "            num_classes=num_classes, \n",
    "            device=device)\n",
    "        \n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "        filter_mask = filter_connected_domain(label_pred,num_keep_region=None,ratio_keep=0.001)\n",
    "        filter_mask = (filter_mask>0).astype(float)\n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "        label_pred = label_pred*filter_mask\n",
    "\n",
    "        # 发现圆形视场的边界处经常出现错误分割(轮廓线),因此需要手动过滤\n",
    "        r = label_pred.shape[0]/2\n",
    "        xc,yc = label_pred.shape[0]/2,label_pred.shape[0]/2\n",
    "#         filter_mask = np.ones(label_pred.shape)\n",
    "#         for x in range(label_pred.shape[0]):\n",
    "#             for y in range(label_pred.shape[1]):\n",
    "#                 filter_mask[x,y,:] = 0 if r*0.5<np.sqrt((x-xc)**2+(y-yc)**2)<r*2 else 1\n",
    "#         label_pred = filter_mask*label_pred\n",
    "        \n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "        # onehot\n",
    "        label_onehot_pred = tf.keras.utils.to_categorical(label_pred)\n",
    "        if not label_onehot_pred.shape[-1]==3:\n",
    "            print(id+' onehot shape error: miss one or more pixel class')\n",
    "            continue\n",
    "            \n",
    "        # center cut\n",
    "        tempL = np.nonzero(label_pred)\n",
    "        minx, maxx = np.min(tempL[0]).astype(int), np.max(tempL[0]).astype(int)\n",
    "        miny, maxy = np.min(tempL[1]).astype(int), np.max(tempL[1]).astype(int)\n",
    "        minz, maxz = np.min(tempL[2]).astype(int), np.max(tempL[2]).astype(int)\n",
    "        image = image[minx:maxx+1, miny:maxy+1, minz:maxz+1]\n",
    "        label_pred = label_pred[minx:maxx+1, miny:maxy+1, minz:maxz+1]\n",
    "        label_onehot_pred = label_onehot_pred[minx:maxx+1, miny:maxy+1, minz:maxz+1, :]\n",
    "            \n",
    "        # case 拼接\n",
    "        numd = []\n",
    "        for d in range(label_pred.shape[2]):\n",
    "            numd.append( len(np.where(label_pred[:,:,d].flatten()==2)[0]) )\n",
    "        numd = np.array(numd)\n",
    "        slice = int(np.where(numd==numd.max())[0][0])\n",
    "        fig = plt.figure( frameon=False)#dpi=100, \n",
    "        image_unstd = (image-image.min())/(image.max()-image.min())*255\n",
    "        npimg = np.append( image_unstd[:,:,slice],label_pred[:,:,slice]/2*255,axis=1 )\n",
    "        plt.imshow(npimg.astype(int),cmap='plasma')#一定要转为int\n",
    "        plt.savefig( test_save_path + id + str(slice) + \"_pred.png\" )\n",
    "        plt.show()\n",
    "        \n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "        \n",
    "        if save_result:\n",
    "            # save files\n",
    "            filename = os.path.join(os.path.dirname(image_path),'center_cut.h5')\n",
    "            f = h5py.File(filename, 'w')\n",
    "            f.create_dataset('image', data=image.astype(np.float32), compression=\"gzip\")\n",
    "#             f.create_dataset('label', data=label_onehot_pred.astype(np.int), compression=\"gzip\")\n",
    "            f.close()\n",
    "#             nib.save(nib.Nifti1Image(image[:].astype(np.float32), np.eye(4)), \n",
    "#                      out_dir+ '/' + id +'_minx%d_maxx%d_miny%d_maxy%d_minz%d_maxz%d'%(minx,maxx,miny,maxy,minz,maxz)+ \"_img.nii.gz\")\n",
    "#             nib.save(nib.Nifti1Image(label_pred.astype(np.float32), np.eye(4)), \n",
    "#                      out_dir+ '/' + id +'_minx%d_maxx%d_miny%d_maxy%d_minz%d_maxz%d'%(minx,maxx,miny,maxy,minz,maxz)+ \"_pred.nii.gz\")\n",
    "#             nib.save(nib.Nifti1Image(label_onehot_pred[:].astype(np.float32), np.eye(4)), \n",
    "#                      out_dir+ '/' + id +'_minx%d_maxx%d_miny%d_maxy%d_minz%d_maxz%d'%(minx,maxx,miny,maxy,minz,maxz)+ \"_label_onehot_pred.nii.gz\")\n",
    "    print('All finished')\n",
    "\n",
    "\n",
    "# -\n",
    "\n",
    "from skimage import measure\n",
    "def filter_connected_domain(image,num_keep_region=100,ratio_keep=None):\n",
    "    \"\"\"\n",
    "    原文链接：https://blog.csdn.net/a563562675/article/details/107066836\n",
    "    return label of filter \n",
    "    \"\"\"\n",
    "    # 标记输入的3D图像\n",
    "    label, num = measure.label(image, connectivity=1, background=0, return_num=True)\n",
    "    if num < 1:\n",
    "        return image\n",
    "\n",
    "    # 获取对应的region对象\n",
    "    region = measure.regionprops(label)\n",
    "    # 获取每一块区域面积并排序\n",
    "    num_list = [i for i in range(0, num)]\n",
    "    area_list = [region[i].area for i in num_list]\n",
    "    \n",
    "    # 去除面积较小的连通域\n",
    "    if ratio_keep:\n",
    "        max_region_area = np.array(area_list).max()\n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "        drop_list = np.where(area_list<max_region_area*ratio_keep)[0]\n",
    "        for i in drop_list:\n",
    "            label[region[i-1].slice][region[i-1].image] = 0 \n",
    "    \n",
    "    else:\n",
    "        if len(num_list) > num_keep_region:\n",
    "            num_list_sorted = sorted(num_list, key=lambda x: area_list[x])[::-1]# 面积由大到小排序\n",
    "            for i in num_list_sorted[num_keep_region:]:\n",
    "                # label[label==i] = 0\n",
    "                label[region[i-1].slice][region[i-1].image] = 0\n",
    "#             num_list_sorted = num_list_sorted[:num_keep_region]\n",
    "    import pdb\n",
    "    pdb.set_trace()\n",
    "    return label\n",
    "\n",
    "\n",
    "def test_all_case(\n",
    "    net, image_list, \n",
    "    num_classes, patch_size=(112, 112, 80), stride_xy=18, stride_z=4, \n",
    "    save_result=True, test_save_path=None, preproc_fn=None,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    \n",
    "    metrics = pd.DataFrame(columns=['bg','proximal_femur','distal_femur','fragment']) \n",
    "    total_metric = 0.0\n",
    "    for image_path in tqdm(image_list):\n",
    "        id = image_path.split('/')[-2]\n",
    "        h5f = h5py.File(image_path, 'r')\n",
    "        print('image_path:',image_path)\n",
    "        image = h5f['image'][:]\n",
    "        label = np.argmax(h5f['label'][:],axis=-1)#非onehot\n",
    "        print('label:',label.shape)\n",
    "        print('image:',image.shape)\n",
    "        if preproc_fn is not None:\n",
    "            image = preproc_fn(image)\n",
    "        prediction, score_map = test_single_case(net, image, stride_xy, stride_z, patch_size, num_classes=num_classes, device=\"cuda\")\n",
    "\n",
    "        print('prediction:',prediction.shape)\n",
    "        \n",
    "        if np.sum(prediction)==0:\n",
    "            single_metric = (0,0,0,0)\n",
    "        else:\n",
    "            single_metric = calculate_metric_percase(prediction, label[:], num_classes)\n",
    "        total_metric += np.asarray(single_metric)\n",
    "        \n",
    "        print(id,':')\n",
    "        print(\"single_metric:\",single_metric)\n",
    "        \n",
    "        metrics.loc[id] = single_metric\n",
    "        if save_result:\n",
    "            nib.save(nib.Nifti1Image(prediction.astype(np.float32), np.eye(4)), test_save_path + id + \"_pred.nii.gz\")\n",
    "            nib.save(nib.Nifti1Image(image[:].astype(np.float32), np.eye(4)), test_save_path + id + \"_img.nii.gz\")\n",
    "            nib.save(nib.Nifti1Image(label[:].astype(np.float32), np.eye(4)), test_save_path + id + \"_gt.nii.gz\")\n",
    "    avg_metric = total_metric / len(image_list)\n",
    "    print('average metric is:\\n{}'.format(avg_metric))\n",
    "\n",
    "    return avg_metric, metrics\n",
    "\n",
    "\n",
    "def test_single_case(net, image, stride_xy, stride_z, patch_size, num_classes=1, device=\"cuda\"):\n",
    "    w, h, d = image.shape\n",
    "\n",
    "    # if the size of image is less than patch_size, then padding it\n",
    "    add_pad = False\n",
    "    if w < patch_size[0]:\n",
    "        w_pad = patch_size[0]-w\n",
    "        add_pad = True\n",
    "    else:\n",
    "        w_pad = 0\n",
    "    if h < patch_size[1]:\n",
    "        h_pad = patch_size[1]-h\n",
    "        add_pad = True\n",
    "    else:\n",
    "        h_pad = 0\n",
    "    if d < patch_size[2]:\n",
    "        d_pad = patch_size[2]-d\n",
    "        add_pad = True\n",
    "    else:\n",
    "        d_pad = 0\n",
    "    wl_pad, wr_pad = w_pad//2,w_pad-w_pad//2\n",
    "    hl_pad, hr_pad = h_pad//2,h_pad-h_pad//2\n",
    "    dl_pad, dr_pad = d_pad//2,d_pad-d_pad//2\n",
    "    if add_pad:\n",
    "        image = np.pad(image, [(wl_pad,wr_pad),(hl_pad,hr_pad), (dl_pad, dr_pad)], mode='constant', constant_values=0)\n",
    "    ww,hh,dd = image.shape\n",
    "\n",
    "    sx = math.ceil((ww - patch_size[0]) / stride_xy) + 1\n",
    "    sy = math.ceil((hh - patch_size[1]) / stride_xy) + 1\n",
    "    sz = math.ceil((dd - patch_size[2]) / stride_z) + 1\n",
    "    print(\"{}, {}, {}\".format(sx, sy, sz))\n",
    "    score_map = np.zeros((num_classes, ) + image.shape).astype(np.float32)\n",
    "    cnt = np.zeros(image.shape).astype(np.float32)\n",
    "\n",
    "    for x in range(0, sx):\n",
    "        xs = min(stride_xy*x, ww-patch_size[0])\n",
    "        for y in range(0, sy):\n",
    "            ys = min(stride_xy * y,hh-patch_size[1])\n",
    "            for z in range(0, sz):\n",
    "                zs = min(stride_z * z, dd-patch_size[2])\n",
    "                test_patch = image[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]]\n",
    "                test_patch = np.expand_dims(np.expand_dims(test_patch,axis=0),axis=0).astype(np.float32)\n",
    "                #test_patch = torch.from_numpy(test_patch).cuda()# gpu\n",
    "                test_patch = torch.from_numpy(test_patch).to(device)# cpu\n",
    "                y1 = net(test_patch)\n",
    "                y = F.softmax(y1, dim=1)\n",
    "                y = y.cpu().data.numpy()\n",
    "                y = y[0,:,:,:,:]\n",
    "                score_map[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] += y\n",
    "                cnt[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] += 1\n",
    "    score_map = score_map/np.expand_dims(cnt,axis=0)\n",
    "    label_map = np.argmax(score_map, axis = 0)\n",
    "    if add_pad:\n",
    "        label_map = label_map[wl_pad:wl_pad+w,hl_pad:hl_pad+h,dl_pad:dl_pad+d]\n",
    "        score_map = score_map[:,wl_pad:wl_pad+w,hl_pad:hl_pad+h,dl_pad:dl_pad+d]\n",
    "    return label_map, score_map\n",
    "\n",
    "def cal_dice(prediction, label, num=2):\n",
    "    total_dice = np.zeros(num-1)\n",
    "    for i in range(1, num):\n",
    "        prediction_tmp = (prediction==i)\n",
    "        label_tmp = (label==i)\n",
    "        prediction_tmp = prediction_tmp.astype(np.float)\n",
    "        label_tmp = label_tmp.astype(np.float)\n",
    "\n",
    "        dice = 2 * np.sum(prediction_tmp * label_tmp) / (np.sum(prediction_tmp) + np.sum(label_tmp))\n",
    "        total_dice[i - 1] += dice\n",
    "\n",
    "    return total_dice\n",
    "\n",
    "def calculate_metric_percase(pred, gt, num_classes):\n",
    "    \"二分类、多分类的指标统计\"\n",
    "    if num_classes is None:\n",
    "        num_classes = len(np.unique(gt))#注意：gt不是onehot编码\n",
    "    print('np.unique(gt):',np.unique(gt))\n",
    "    if num_classes==2:\n",
    "        dice = metric.binary.dc(pred, gt)\n",
    "        jc = metric.binary.jc(pred, gt)\n",
    "        hd = metric.binary.hd95(pred, gt)\n",
    "        asd = metric.binary.asd(pred, gt)\n",
    "    elif num_classes>2:\n",
    "        from keras.utils import to_categorical\n",
    "        gt_onehot = to_categorical(gt, num_classes)\n",
    "        pred_onehot = to_categorical(pred, num_classes)\n",
    "        dice = []\n",
    "        jc = []\n",
    "        hd = []\n",
    "        asd = []\n",
    "        for k in range(num_classes):\n",
    "            pred_k = pred_onehot[...,k]\n",
    "            gt_k = gt_onehot[...,k]\n",
    "            dice +=  [metric.dc(result=pred_k, reference=gt_k)]\n",
    "            #jc += [metric.jc(result=pred_k, reference=gt_k)]\n",
    "            #hd += [metric.hd95(result=pred_k, reference=gt_k)]\n",
    "            #asd += [metric.asd(result=pred_k, reference=gt_k)]\n",
    "    else:\n",
    "        raise ValueError(\"pred和gt不能是onehot编码\")\n",
    "    return dice#, jc#, hd, asd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "uuid": "70d9ca85-faac-4a93-a91e-e9543426f664"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--root_path', type=str, default='../../data/gz_dataset/segmented', help='Folder of Test Set')\n",
    "parser.add_argument('--model', type=str,  default='vnet_supervisedonly_dp', help='model_name')\n",
    "parser.add_argument('--gpu', type=str,  default='0', help='GPU to use')\n",
    "FLAGS = parser.parse_args(args=[])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "uuid": "f364d364-45f2-4cc2-83d1-732ff387ded2"
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = FLAGS.gpu\n",
    "snapshot_path = \"../model/\"+FLAGS.model+\"/\"\n",
    "test_save_path = \"../model/prediction/\"+FLAGS.model+\"_post/\"\n",
    "if not os.path.exists(test_save_path):\n",
    "    os.makedirs(test_save_path)\n",
    "\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "uuid": "9efa40ba-ef48-43a8-b1c2-e0be4a856ae4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_list:  ['../../data/gz_dataset/segmented/100207091/mri_norm2.h5', '../../data/gz_dataset/segmented/100301649/mri_norm2.h5', '../../data/gz_dataset/segmented/100658440/mri_norm2.h5', '../../data/gz_dataset/segmented/100752370/mri_norm2.h5', '../../data/gz_dataset/segmented/100903938/mri_norm2.h5', '../../data/gz_dataset/segmented/100067245/mri_norm2.h5', '../../data/gz_dataset/segmented/100218737/mri_norm2.h5', '../../data/gz_dataset/segmented/100201344/mri_norm2.h5']\n"
     ]
    }
   ],
   "source": [
    "with open(FLAGS.root_path + '/../test.list', 'r') as f:\n",
    "    image_list = f.readlines()\n",
    "image_list = [os.path.join(FLAGS.root_path,item.replace('\\n', ''),\"mri_norm2.h5\") for item in image_list]\n",
    "print(\"image_list: \",image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "uuid": "5f0aad66-fe7a-4f78-b722-8f156eb23ac6"
   },
   "outputs": [],
   "source": [
    "def test_calculate_metric(epoch_num, patch_size=(128, 128, 64), stride_xy=64, stride_z=32):\n",
    "    print(\"test_calculate_metric\")\n",
    "    net = VNet(n_channels=1, n_classes=num_classes, normalization='batchnorm', has_dropout=False).cuda()\n",
    "    save_mode_path = os.path.join(snapshot_path, 'iter_' + str(epoch_num) + '.pth')\n",
    "    net.load_state_dict(torch.load(save_mode_path))\n",
    "    print(\"init weight from {}\".format(save_mode_path))\n",
    "    net.eval()\n",
    "\n",
    "    avg_metric,metrics = test_all_case(net, image_list, num_classes=num_classes,\n",
    "                               patch_size=patch_size, stride_xy=stride_xy, stride_z=stride_z,\n",
    "                               save_result=True, test_save_path=test_save_path)\n",
    "\n",
    "    return avg_metric, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "uuid": "46eef4b6-488c-449d-866c-c49c2d500534"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin\n",
      "test_calculate_metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init weight from ../model/vnet_supervisedonly_dp/iter_6001.pth\n",
      "image_path: ../../data/gz_dataset/segmented/100207091/mri_norm2.h5\n",
      "label: (160, 156, 173)\n",
      "image: (160, 156, 173)\n",
      "2, 2, 5\n",
      "prediction: (160, 156, 173)\n",
      "np.unique(gt): [0 1 2 3]\n",
      "100207091 :\n",
      "single_metric: [0.9964821321267388, 0.936998244364846, 0.882832511995007, 0.8798208161265486]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:03<00:25,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_path: ../../data/gz_dataset/segmented/100301649/mri_norm2.h5\n",
      "label: (159, 147, 111)\n",
      "image: (159, 147, 111)\n",
      "2, 2, 3\n",
      "prediction: (159, 147, 111)\n",
      "np.unique(gt): [0 1 2 3]\n",
      "100301649 :\n",
      "single_metric: [0.9942182885121614, 0.8605200173175732, 0.8919104072082951, 0.8776530242665701]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [00:05<00:19,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_path: ../../data/gz_dataset/segmented/100658440/mri_norm2.h5\n",
      "label: (153, 152, 101)\n",
      "image: (153, 152, 101)\n",
      "2, 2, 3\n",
      "prediction: (153, 152, 101)\n",
      "np.unique(gt): [0 1 2 3]\n",
      "100658440 :\n",
      "single_metric: [0.9964006552533198, 0.9115636438624529, 0.8747342332708493, 0.7633284607110351]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [00:07<00:14,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_path: ../../data/gz_dataset/segmented/100752370/mri_norm2.h5\n",
      "label: (155, 164, 104)\n",
      "image: (155, 164, 104)\n",
      "2, 2, 3\n",
      "prediction: (155, 164, 104)\n",
      "np.unique(gt): [0 1 2 3]\n",
      "100752370 :\n",
      "single_metric: [0.9972625500179719, 0.9412957517996553, 0.8523607645048458, 0.7841802543401404]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [00:10<00:10,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_path: ../../data/gz_dataset/segmented/100903938/mri_norm2.h5\n",
      "label: (154, 155, 112)\n",
      "image: (154, 155, 112)\n",
      "2, 2, 3\n",
      "prediction: (154, 155, 112)\n",
      "np.unique(gt): [0 1 2 3]\n",
      "100903938 :\n",
      "single_metric: [0.996094557520676, 0.9067374527940452, 0.8747810858143608, 0.774058201216771]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [00:12<00:07,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_path: ../../data/gz_dataset/segmented/100067245/mri_norm2.h5\n",
      "label: (149, 141, 133)\n",
      "image: (149, 141, 133)\n",
      "2, 2, 4\n",
      "prediction: (149, 141, 133)\n",
      "np.unique(gt): [0 1 2 3]\n",
      "100067245 :\n",
      "single_metric: [0.9982776232184414, 0.9301743207334549, 0.8977240387351839, 0.7450028270196561]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [00:14<00:05,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_path: ../../data/gz_dataset/segmented/100218737/mri_norm2.h5\n",
      "label: (155, 155, 91)\n",
      "image: (155, 155, 91)\n",
      "2, 2, 2\n",
      "prediction: (155, 155, 91)\n",
      "np.unique(gt): [0 1 2 3]\n",
      "100218737 :\n",
      "single_metric: [0.9962799382192356, 0.9640275774678416, 0.7800531600073176, 0.42676848022059605]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [00:16<00:02,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_path: ../../data/gz_dataset/segmented/100201344/mri_norm2.h5\n",
      "label: (156, 155, 109)\n",
      "image: (156, 155, 109)\n",
      "2, 2, 3\n",
      "prediction: (156, 155, 109)\n",
      "np.unique(gt): [0 1 2 3]\n",
      "100201344 :\n",
      "single_metric: [0.9941842765785757, 0.9262981183986569, 0.8191332867099139, 0.8049699060223153]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:18<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average metric is:\n",
      "[0.99615    0.92220189 0.85919119 0.75697275]\n",
      "[0.99615    0.92220189 0.85919119 0.75697275]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"begin\")\n",
    "avg_metric, metrics = test_calculate_metric(6001, patch_size=(128, 128, 64), stride_xy=64, stride_z=32)\n",
    "print(avg_metric)\n",
    "metrics.to_csv(os.path.join(test_save_path,'metrics_test_set.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "uuid": "8122a1be-56f2-4620-a990-2009c8a8ffd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 bg  proximal_femur  distal_femur  fragment\n",
      "100207091  0.996482        0.936998      0.882833  0.879821\n",
      "100301649  0.994218        0.860520      0.891910  0.877653\n",
      "100658440  0.996401        0.911564      0.874734  0.763328\n",
      "100752370  0.997263        0.941296      0.852361  0.784180\n",
      "100903938  0.996095        0.906737      0.874781  0.774058\n",
      "100067245  0.998278        0.930174      0.897724  0.745003\n",
      "100218737  0.996280        0.964028      0.780053  0.426768\n",
      "100201344  0.994184        0.926298      0.819133  0.804970\n"
     ]
    }
   ],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "11c220eb-0222-445b-8d9b-96b2e76e9dda"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
